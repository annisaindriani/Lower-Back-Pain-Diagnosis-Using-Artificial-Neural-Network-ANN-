{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library untuk melakukan data analysis dan data exploration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk load dataset dari file .csv\n",
    "spine = pd.read_csv(\"dataset_spine.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 310 entries, 0 to 309\n",
      "Data columns (total 14 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  310 non-null    int64  \n",
      " 1   Col1        310 non-null    float64\n",
      " 2   Col2        310 non-null    float64\n",
      " 3   Col3        310 non-null    float64\n",
      " 4   Col4        310 non-null    float64\n",
      " 5   Col5        310 non-null    float64\n",
      " 6   Col6        310 non-null    float64\n",
      " 7   Col7        310 non-null    float64\n",
      " 8   Col8        310 non-null    float64\n",
      " 9   Col9        310 non-null    float64\n",
      " 10  Col10       310 non-null    float64\n",
      " 11  Col11       310 non-null    float64\n",
      " 12  Col12       310 non-null    float64\n",
      " 13  Class_att   310 non-null    object \n",
      "dtypes: float64(12), int64(1), object(1)\n",
      "memory usage: 34.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Untuk melihat tipe data dan jumlah kolom\n",
    "spine.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset ini terdiri dari 14 variabel, dimana masing-masing variabel terdiri dari 310 baris. Variabel \"Col1\" hingga \"Col12\" memiliki tipe data float64, variabel \"unnamed:0\" memiliki tipe data int 64, dan variabel \"class_att\" memiliki tipe data object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "      <th>Col11</th>\n",
       "      <th>Col12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>310.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>310.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>154.500000</td>\n",
       "      <td>60.496653</td>\n",
       "      <td>17.542822</td>\n",
       "      <td>51.930930</td>\n",
       "      <td>42.953831</td>\n",
       "      <td>117.920655</td>\n",
       "      <td>26.296694</td>\n",
       "      <td>0.472979</td>\n",
       "      <td>21.321526</td>\n",
       "      <td>13.064511</td>\n",
       "      <td>11.933317</td>\n",
       "      <td>-14.053139</td>\n",
       "      <td>25.645981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>89.633513</td>\n",
       "      <td>17.236520</td>\n",
       "      <td>10.008330</td>\n",
       "      <td>18.554064</td>\n",
       "      <td>13.423102</td>\n",
       "      <td>13.317377</td>\n",
       "      <td>37.559027</td>\n",
       "      <td>0.285787</td>\n",
       "      <td>8.639423</td>\n",
       "      <td>3.399713</td>\n",
       "      <td>2.893265</td>\n",
       "      <td>12.225582</td>\n",
       "      <td>10.450558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.147921</td>\n",
       "      <td>-6.554948</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>13.366931</td>\n",
       "      <td>70.082575</td>\n",
       "      <td>-11.058179</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>7.027000</td>\n",
       "      <td>7.037800</td>\n",
       "      <td>7.030600</td>\n",
       "      <td>-35.287375</td>\n",
       "      <td>7.007900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>77.250000</td>\n",
       "      <td>46.430294</td>\n",
       "      <td>10.667069</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>33.347122</td>\n",
       "      <td>110.709196</td>\n",
       "      <td>1.603727</td>\n",
       "      <td>0.224367</td>\n",
       "      <td>13.054400</td>\n",
       "      <td>10.417800</td>\n",
       "      <td>9.541140</td>\n",
       "      <td>-24.289522</td>\n",
       "      <td>17.189075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>154.500000</td>\n",
       "      <td>58.691038</td>\n",
       "      <td>16.357689</td>\n",
       "      <td>49.562398</td>\n",
       "      <td>42.404912</td>\n",
       "      <td>118.268178</td>\n",
       "      <td>11.767934</td>\n",
       "      <td>0.475989</td>\n",
       "      <td>21.907150</td>\n",
       "      <td>12.938450</td>\n",
       "      <td>11.953835</td>\n",
       "      <td>-14.622856</td>\n",
       "      <td>24.931950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>231.750000</td>\n",
       "      <td>72.877696</td>\n",
       "      <td>22.120395</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>52.695888</td>\n",
       "      <td>125.467674</td>\n",
       "      <td>41.287352</td>\n",
       "      <td>0.704846</td>\n",
       "      <td>28.954075</td>\n",
       "      <td>15.889525</td>\n",
       "      <td>14.371810</td>\n",
       "      <td>-3.497094</td>\n",
       "      <td>33.979600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>309.000000</td>\n",
       "      <td>129.834041</td>\n",
       "      <td>49.431864</td>\n",
       "      <td>125.742385</td>\n",
       "      <td>121.429566</td>\n",
       "      <td>163.071041</td>\n",
       "      <td>418.543082</td>\n",
       "      <td>0.998827</td>\n",
       "      <td>36.743900</td>\n",
       "      <td>19.324000</td>\n",
       "      <td>16.821080</td>\n",
       "      <td>6.972071</td>\n",
       "      <td>44.341200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        Col1        Col2        Col3        Col4        Col5  \\\n",
       "count  310.000000  310.000000  310.000000  310.000000  310.000000  310.000000   \n",
       "mean   154.500000   60.496653   17.542822   51.930930   42.953831  117.920655   \n",
       "std     89.633513   17.236520   10.008330   18.554064   13.423102   13.317377   \n",
       "min      0.000000   26.147921   -6.554948   14.000000   13.366931   70.082575   \n",
       "25%     77.250000   46.430294   10.667069   37.000000   33.347122  110.709196   \n",
       "50%    154.500000   58.691038   16.357689   49.562398   42.404912  118.268178   \n",
       "75%    231.750000   72.877696   22.120395   63.000000   52.695888  125.467674   \n",
       "max    309.000000  129.834041   49.431864  125.742385  121.429566  163.071041   \n",
       "\n",
       "             Col6        Col7        Col8        Col9       Col10       Col11  \\\n",
       "count  310.000000  310.000000  310.000000  310.000000  310.000000  310.000000   \n",
       "mean    26.296694    0.472979   21.321526   13.064511   11.933317  -14.053139   \n",
       "std     37.559027    0.285787    8.639423    3.399713    2.893265   12.225582   \n",
       "min    -11.058179    0.003220    7.027000    7.037800    7.030600  -35.287375   \n",
       "25%      1.603727    0.224367   13.054400   10.417800    9.541140  -24.289522   \n",
       "50%     11.767934    0.475989   21.907150   12.938450   11.953835  -14.622856   \n",
       "75%     41.287352    0.704846   28.954075   15.889525   14.371810   -3.497094   \n",
       "max    418.543082    0.998827   36.743900   19.324000   16.821080    6.972071   \n",
       "\n",
       "            Col12  \n",
       "count  310.000000  \n",
       "mean    25.645981  \n",
       "std     10.450558  \n",
       "min      7.007900  \n",
       "25%     17.189075  \n",
       "50%     24.931950  \n",
       "75%     33.979600  \n",
       "max     44.341200  "
      ]
     },
     "execution_count": 885,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Untuk melihat summary statistics pada kolom numerik\n",
    "spine.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Abnormal    210\n",
       "Normal      100\n",
       "Name: Class_att, dtype: int64"
      ]
     },
     "execution_count": 886,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Untuk melihat jumlah unique values pada kolom kategorik variabel \"Class_att\"\n",
    "spine[\"Class_att\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "      <th>Col11</th>\n",
       "      <th>Col12</th>\n",
       "      <th>Class_att</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>63.027817</td>\n",
       "      <td>22.552586</td>\n",
       "      <td>39.609117</td>\n",
       "      <td>40.475232</td>\n",
       "      <td>98.672917</td>\n",
       "      <td>-0.254400</td>\n",
       "      <td>0.744503</td>\n",
       "      <td>12.5661</td>\n",
       "      <td>14.5386</td>\n",
       "      <td>15.30468</td>\n",
       "      <td>-28.658501</td>\n",
       "      <td>43.5123</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>39.056951</td>\n",
       "      <td>10.060991</td>\n",
       "      <td>25.015378</td>\n",
       "      <td>28.995960</td>\n",
       "      <td>114.405425</td>\n",
       "      <td>4.564259</td>\n",
       "      <td>0.415186</td>\n",
       "      <td>12.8874</td>\n",
       "      <td>17.5323</td>\n",
       "      <td>16.78486</td>\n",
       "      <td>-25.530607</td>\n",
       "      <td>16.1102</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>68.832021</td>\n",
       "      <td>22.218482</td>\n",
       "      <td>50.092194</td>\n",
       "      <td>46.613539</td>\n",
       "      <td>105.985135</td>\n",
       "      <td>-3.530317</td>\n",
       "      <td>0.474889</td>\n",
       "      <td>26.8343</td>\n",
       "      <td>17.4861</td>\n",
       "      <td>16.65897</td>\n",
       "      <td>-29.031888</td>\n",
       "      <td>19.2221</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>69.297008</td>\n",
       "      <td>24.652878</td>\n",
       "      <td>44.311238</td>\n",
       "      <td>44.644130</td>\n",
       "      <td>101.868495</td>\n",
       "      <td>11.211523</td>\n",
       "      <td>0.369345</td>\n",
       "      <td>23.5603</td>\n",
       "      <td>12.7074</td>\n",
       "      <td>11.42447</td>\n",
       "      <td>-30.470246</td>\n",
       "      <td>18.8329</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>49.712859</td>\n",
       "      <td>9.652075</td>\n",
       "      <td>28.317406</td>\n",
       "      <td>40.060784</td>\n",
       "      <td>108.168725</td>\n",
       "      <td>7.918501</td>\n",
       "      <td>0.543360</td>\n",
       "      <td>35.4940</td>\n",
       "      <td>15.9546</td>\n",
       "      <td>8.87237</td>\n",
       "      <td>-16.378376</td>\n",
       "      <td>24.9171</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>305</td>\n",
       "      <td>47.903565</td>\n",
       "      <td>13.616688</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>34.286877</td>\n",
       "      <td>117.449062</td>\n",
       "      <td>-4.245395</td>\n",
       "      <td>0.129744</td>\n",
       "      <td>7.8433</td>\n",
       "      <td>14.7484</td>\n",
       "      <td>8.51707</td>\n",
       "      <td>-15.728927</td>\n",
       "      <td>11.5472</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>306</td>\n",
       "      <td>53.936748</td>\n",
       "      <td>20.721496</td>\n",
       "      <td>29.220534</td>\n",
       "      <td>33.215251</td>\n",
       "      <td>114.365845</td>\n",
       "      <td>-0.421010</td>\n",
       "      <td>0.047913</td>\n",
       "      <td>19.1986</td>\n",
       "      <td>18.1972</td>\n",
       "      <td>7.08745</td>\n",
       "      <td>6.013843</td>\n",
       "      <td>43.8693</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>307</td>\n",
       "      <td>61.446597</td>\n",
       "      <td>22.694968</td>\n",
       "      <td>46.170347</td>\n",
       "      <td>38.751628</td>\n",
       "      <td>125.670725</td>\n",
       "      <td>-2.707880</td>\n",
       "      <td>0.081070</td>\n",
       "      <td>16.2059</td>\n",
       "      <td>13.5565</td>\n",
       "      <td>8.89572</td>\n",
       "      <td>3.564463</td>\n",
       "      <td>18.4151</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>308</td>\n",
       "      <td>45.252792</td>\n",
       "      <td>8.693157</td>\n",
       "      <td>41.583126</td>\n",
       "      <td>36.559635</td>\n",
       "      <td>118.545842</td>\n",
       "      <td>0.214750</td>\n",
       "      <td>0.159251</td>\n",
       "      <td>14.7334</td>\n",
       "      <td>16.0928</td>\n",
       "      <td>9.75922</td>\n",
       "      <td>5.767308</td>\n",
       "      <td>33.7192</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>309</td>\n",
       "      <td>33.841641</td>\n",
       "      <td>5.073991</td>\n",
       "      <td>36.641233</td>\n",
       "      <td>28.767649</td>\n",
       "      <td>123.945244</td>\n",
       "      <td>-0.199249</td>\n",
       "      <td>0.674504</td>\n",
       "      <td>19.3825</td>\n",
       "      <td>17.6963</td>\n",
       "      <td>13.72929</td>\n",
       "      <td>1.783007</td>\n",
       "      <td>40.6049</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0       Col1       Col2       Col3       Col4        Col5  \\\n",
       "0             0  63.027817  22.552586  39.609117  40.475232   98.672917   \n",
       "1             1  39.056951  10.060991  25.015378  28.995960  114.405425   \n",
       "2             2  68.832021  22.218482  50.092194  46.613539  105.985135   \n",
       "3             3  69.297008  24.652878  44.311238  44.644130  101.868495   \n",
       "4             4  49.712859   9.652075  28.317406  40.060784  108.168725   \n",
       "..          ...        ...        ...        ...        ...         ...   \n",
       "305         305  47.903565  13.616688  36.000000  34.286877  117.449062   \n",
       "306         306  53.936748  20.721496  29.220534  33.215251  114.365845   \n",
       "307         307  61.446597  22.694968  46.170347  38.751628  125.670725   \n",
       "308         308  45.252792   8.693157  41.583126  36.559635  118.545842   \n",
       "309         309  33.841641   5.073991  36.641233  28.767649  123.945244   \n",
       "\n",
       "          Col6      Col7     Col8     Col9     Col10      Col11    Col12  \\\n",
       "0    -0.254400  0.744503  12.5661  14.5386  15.30468 -28.658501  43.5123   \n",
       "1     4.564259  0.415186  12.8874  17.5323  16.78486 -25.530607  16.1102   \n",
       "2    -3.530317  0.474889  26.8343  17.4861  16.65897 -29.031888  19.2221   \n",
       "3    11.211523  0.369345  23.5603  12.7074  11.42447 -30.470246  18.8329   \n",
       "4     7.918501  0.543360  35.4940  15.9546   8.87237 -16.378376  24.9171   \n",
       "..         ...       ...      ...      ...       ...        ...      ...   \n",
       "305  -4.245395  0.129744   7.8433  14.7484   8.51707 -15.728927  11.5472   \n",
       "306  -0.421010  0.047913  19.1986  18.1972   7.08745   6.013843  43.8693   \n",
       "307  -2.707880  0.081070  16.2059  13.5565   8.89572   3.564463  18.4151   \n",
       "308   0.214750  0.159251  14.7334  16.0928   9.75922   5.767308  33.7192   \n",
       "309  -0.199249  0.674504  19.3825  17.6963  13.72929   1.783007  40.6049   \n",
       "\n",
       "    Class_att  \n",
       "0    Abnormal  \n",
       "1    Abnormal  \n",
       "2    Abnormal  \n",
       "3    Abnormal  \n",
       "4    Abnormal  \n",
       "..        ...  \n",
       "305    Normal  \n",
       "306    Normal  \n",
       "307    Normal  \n",
       "308    Normal  \n",
       "309    Normal  \n",
       "\n",
       "[310 rows x 14 columns]"
      ]
     },
     "execution_count": 887,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Untuk melihat lima baris pertamadan terakhir pada data\n",
    "spine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "      <th>Col11</th>\n",
       "      <th>Col12</th>\n",
       "      <th>Class_att</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.027817</td>\n",
       "      <td>22.552586</td>\n",
       "      <td>39.609117</td>\n",
       "      <td>40.475232</td>\n",
       "      <td>98.672917</td>\n",
       "      <td>-0.254400</td>\n",
       "      <td>0.744503</td>\n",
       "      <td>12.5661</td>\n",
       "      <td>14.5386</td>\n",
       "      <td>15.30468</td>\n",
       "      <td>-28.658501</td>\n",
       "      <td>43.5123</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.056951</td>\n",
       "      <td>10.060991</td>\n",
       "      <td>25.015378</td>\n",
       "      <td>28.995960</td>\n",
       "      <td>114.405425</td>\n",
       "      <td>4.564259</td>\n",
       "      <td>0.415186</td>\n",
       "      <td>12.8874</td>\n",
       "      <td>17.5323</td>\n",
       "      <td>16.78486</td>\n",
       "      <td>-25.530607</td>\n",
       "      <td>16.1102</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.832021</td>\n",
       "      <td>22.218482</td>\n",
       "      <td>50.092194</td>\n",
       "      <td>46.613539</td>\n",
       "      <td>105.985135</td>\n",
       "      <td>-3.530317</td>\n",
       "      <td>0.474889</td>\n",
       "      <td>26.8343</td>\n",
       "      <td>17.4861</td>\n",
       "      <td>16.65897</td>\n",
       "      <td>-29.031888</td>\n",
       "      <td>19.2221</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.297008</td>\n",
       "      <td>24.652878</td>\n",
       "      <td>44.311238</td>\n",
       "      <td>44.644130</td>\n",
       "      <td>101.868495</td>\n",
       "      <td>11.211523</td>\n",
       "      <td>0.369345</td>\n",
       "      <td>23.5603</td>\n",
       "      <td>12.7074</td>\n",
       "      <td>11.42447</td>\n",
       "      <td>-30.470246</td>\n",
       "      <td>18.8329</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.712859</td>\n",
       "      <td>9.652075</td>\n",
       "      <td>28.317406</td>\n",
       "      <td>40.060784</td>\n",
       "      <td>108.168725</td>\n",
       "      <td>7.918501</td>\n",
       "      <td>0.543360</td>\n",
       "      <td>35.4940</td>\n",
       "      <td>15.9546</td>\n",
       "      <td>8.87237</td>\n",
       "      <td>-16.378376</td>\n",
       "      <td>24.9171</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Col1       Col2       Col3       Col4        Col5       Col6  \\\n",
       "0  63.027817  22.552586  39.609117  40.475232   98.672917  -0.254400   \n",
       "1  39.056951  10.060991  25.015378  28.995960  114.405425   4.564259   \n",
       "2  68.832021  22.218482  50.092194  46.613539  105.985135  -3.530317   \n",
       "3  69.297008  24.652878  44.311238  44.644130  101.868495  11.211523   \n",
       "4  49.712859   9.652075  28.317406  40.060784  108.168725   7.918501   \n",
       "\n",
       "       Col7     Col8     Col9     Col10      Col11    Col12 Class_att  \n",
       "0  0.744503  12.5661  14.5386  15.30468 -28.658501  43.5123  Abnormal  \n",
       "1  0.415186  12.8874  17.5323  16.78486 -25.530607  16.1102  Abnormal  \n",
       "2  0.474889  26.8343  17.4861  16.65897 -29.031888  19.2221  Abnormal  \n",
       "3  0.369345  23.5603  12.7074  11.42447 -30.470246  18.8329  Abnormal  \n",
       "4  0.543360  35.4940  15.9546   8.87237 -16.378376  24.9171  Abnormal  "
      ]
     },
     "execution_count": 888,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Untuk menghapus variabel atau kolom yang tidak diperlukan\n",
    "spine = spine.drop([\"Unnamed: 0\"], axis = 1)\n",
    "spine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variabel \"Unnamed: 0\" adalah sebuah ID unik yang tidak terkait dengan variabel target secara langsung sehingga dihapus karena dianggap kurang relevan dalam memprediksi target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "      <th>Col11</th>\n",
       "      <th>Col12</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.027817</td>\n",
       "      <td>22.552586</td>\n",
       "      <td>39.609117</td>\n",
       "      <td>40.475232</td>\n",
       "      <td>98.672917</td>\n",
       "      <td>-0.254400</td>\n",
       "      <td>0.744503</td>\n",
       "      <td>12.5661</td>\n",
       "      <td>14.5386</td>\n",
       "      <td>15.30468</td>\n",
       "      <td>-28.658501</td>\n",
       "      <td>43.5123</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.056951</td>\n",
       "      <td>10.060991</td>\n",
       "      <td>25.015378</td>\n",
       "      <td>28.995960</td>\n",
       "      <td>114.405425</td>\n",
       "      <td>4.564259</td>\n",
       "      <td>0.415186</td>\n",
       "      <td>12.8874</td>\n",
       "      <td>17.5323</td>\n",
       "      <td>16.78486</td>\n",
       "      <td>-25.530607</td>\n",
       "      <td>16.1102</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.832021</td>\n",
       "      <td>22.218482</td>\n",
       "      <td>50.092194</td>\n",
       "      <td>46.613539</td>\n",
       "      <td>105.985135</td>\n",
       "      <td>-3.530317</td>\n",
       "      <td>0.474889</td>\n",
       "      <td>26.8343</td>\n",
       "      <td>17.4861</td>\n",
       "      <td>16.65897</td>\n",
       "      <td>-29.031888</td>\n",
       "      <td>19.2221</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.297008</td>\n",
       "      <td>24.652878</td>\n",
       "      <td>44.311238</td>\n",
       "      <td>44.644130</td>\n",
       "      <td>101.868495</td>\n",
       "      <td>11.211523</td>\n",
       "      <td>0.369345</td>\n",
       "      <td>23.5603</td>\n",
       "      <td>12.7074</td>\n",
       "      <td>11.42447</td>\n",
       "      <td>-30.470246</td>\n",
       "      <td>18.8329</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.712859</td>\n",
       "      <td>9.652075</td>\n",
       "      <td>28.317406</td>\n",
       "      <td>40.060784</td>\n",
       "      <td>108.168725</td>\n",
       "      <td>7.918501</td>\n",
       "      <td>0.543360</td>\n",
       "      <td>35.4940</td>\n",
       "      <td>15.9546</td>\n",
       "      <td>8.87237</td>\n",
       "      <td>-16.378376</td>\n",
       "      <td>24.9171</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Col1       Col2       Col3       Col4        Col5       Col6  \\\n",
       "0  63.027817  22.552586  39.609117  40.475232   98.672917  -0.254400   \n",
       "1  39.056951  10.060991  25.015378  28.995960  114.405425   4.564259   \n",
       "2  68.832021  22.218482  50.092194  46.613539  105.985135  -3.530317   \n",
       "3  69.297008  24.652878  44.311238  44.644130  101.868495  11.211523   \n",
       "4  49.712859   9.652075  28.317406  40.060784  108.168725   7.918501   \n",
       "\n",
       "       Col7     Col8     Col9     Col10      Col11    Col12    Target  \n",
       "0  0.744503  12.5661  14.5386  15.30468 -28.658501  43.5123  Abnormal  \n",
       "1  0.415186  12.8874  17.5323  16.78486 -25.530607  16.1102  Abnormal  \n",
       "2  0.474889  26.8343  17.4861  16.65897 -29.031888  19.2221  Abnormal  \n",
       "3  0.369345  23.5603  12.7074  11.42447 -30.470246  18.8329  Abnormal  \n",
       "4  0.543360  35.4940  15.9546   8.87237 -16.378376  24.9171  Abnormal  "
      ]
     },
     "execution_count": 889,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Untuk mengganti nama variabel atau kolom\n",
    "spine.rename(columns = {\"Class_att\": \"Target\"}, inplace = True)\n",
    "spine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variabel \"Class_att\" diubah menjadi \"Target\" untuk memudahkan dalam memproses data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows:  (0, 13)\n"
     ]
    }
   ],
   "source": [
    "# Untuk melihat apakah ada duplicate rows\n",
    "spine_duplicate = spine[spine.duplicated()]\n",
    "print(\"Number of duplicate rows: \", spine_duplicate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output tersebut, terlihat bahwa tidak ada baris yang memiliki nilai yang sama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col1      0\n",
      "Col2      0\n",
      "Col3      0\n",
      "Col4      0\n",
      "Col5      0\n",
      "Col6      0\n",
      "Col7      0\n",
      "Col8      0\n",
      "Col9      0\n",
      "Col10     0\n",
      "Col11     0\n",
      "Col12     0\n",
      "Target    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Untuk melihat apakah ada missing value\n",
    "print(spine.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output tersebut, terlihat bahwa tidak ada baris yang memiliki missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Untuk melihat plot distribusi dari variabel \"Target\"\n",
    "plt.figure(figsize = (4, 4))\n",
    "plt.title(\"Distributions of Target\")\n",
    "sns.countplot(x = \"Target\", data = spine, palette = \"Spectral\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Untuk melihat plot persentase distribusi dari variabel \"Target\"\n",
    "target_abnormal = spine[spine[\"Target\"] == \"Abnormal\"]\n",
    "target_normal = spine[spine[\"Target\"] == \"Normal\"]\n",
    "\n",
    "ptg_abnormal = (len(target_abnormal)/len(spine)) * 100\n",
    "ptg_normal = (len(target_normal)/len(spine)) * 100\n",
    "\n",
    "y = np.array([ptg_abnormal, ptg_normal])\n",
    "labels = [\"Abnormal\", \"Normal\"]\n",
    "\n",
    "plt.figure(figsize = (8,10))\n",
    "plt.pie(y, labels = labels, autopct = '%1.1f%%', colors = [\"lightsteelblue\", \"lavender\"])\n",
    "plt.title('Percentage of Target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari kedua plot tersebut, terlihat bahwa distribusi dari variabel target tidak merata. Kelas \"Abnormal\" memiliki persentase sekitar 67,7% sedangkan kelas \"Normal\" hanya memiliki persentase sekitar 32,3%. Hal tersebut menunjukkan bahwa dataset tersebut mengalami ketidakseimbangan (imbalanced)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "      <th>Col11</th>\n",
       "      <th>Col12</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.027817</td>\n",
       "      <td>22.552586</td>\n",
       "      <td>39.609117</td>\n",
       "      <td>40.475232</td>\n",
       "      <td>98.672917</td>\n",
       "      <td>-0.254400</td>\n",
       "      <td>0.744503</td>\n",
       "      <td>12.5661</td>\n",
       "      <td>14.5386</td>\n",
       "      <td>15.30468</td>\n",
       "      <td>-28.658501</td>\n",
       "      <td>43.5123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.056951</td>\n",
       "      <td>10.060991</td>\n",
       "      <td>25.015378</td>\n",
       "      <td>28.995960</td>\n",
       "      <td>114.405425</td>\n",
       "      <td>4.564259</td>\n",
       "      <td>0.415186</td>\n",
       "      <td>12.8874</td>\n",
       "      <td>17.5323</td>\n",
       "      <td>16.78486</td>\n",
       "      <td>-25.530607</td>\n",
       "      <td>16.1102</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.832021</td>\n",
       "      <td>22.218482</td>\n",
       "      <td>50.092194</td>\n",
       "      <td>46.613539</td>\n",
       "      <td>105.985135</td>\n",
       "      <td>-3.530317</td>\n",
       "      <td>0.474889</td>\n",
       "      <td>26.8343</td>\n",
       "      <td>17.4861</td>\n",
       "      <td>16.65897</td>\n",
       "      <td>-29.031888</td>\n",
       "      <td>19.2221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.297008</td>\n",
       "      <td>24.652878</td>\n",
       "      <td>44.311238</td>\n",
       "      <td>44.644130</td>\n",
       "      <td>101.868495</td>\n",
       "      <td>11.211523</td>\n",
       "      <td>0.369345</td>\n",
       "      <td>23.5603</td>\n",
       "      <td>12.7074</td>\n",
       "      <td>11.42447</td>\n",
       "      <td>-30.470246</td>\n",
       "      <td>18.8329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.712859</td>\n",
       "      <td>9.652075</td>\n",
       "      <td>28.317406</td>\n",
       "      <td>40.060784</td>\n",
       "      <td>108.168725</td>\n",
       "      <td>7.918501</td>\n",
       "      <td>0.543360</td>\n",
       "      <td>35.4940</td>\n",
       "      <td>15.9546</td>\n",
       "      <td>8.87237</td>\n",
       "      <td>-16.378376</td>\n",
       "      <td>24.9171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Col1       Col2       Col3       Col4        Col5       Col6  \\\n",
       "0  63.027817  22.552586  39.609117  40.475232   98.672917  -0.254400   \n",
       "1  39.056951  10.060991  25.015378  28.995960  114.405425   4.564259   \n",
       "2  68.832021  22.218482  50.092194  46.613539  105.985135  -3.530317   \n",
       "3  69.297008  24.652878  44.311238  44.644130  101.868495  11.211523   \n",
       "4  49.712859   9.652075  28.317406  40.060784  108.168725   7.918501   \n",
       "\n",
       "       Col7     Col8     Col9     Col10      Col11    Col12  Target  \n",
       "0  0.744503  12.5661  14.5386  15.30468 -28.658501  43.5123       0  \n",
       "1  0.415186  12.8874  17.5323  16.78486 -25.530607  16.1102       0  \n",
       "2  0.474889  26.8343  17.4861  16.65897 -29.031888  19.2221       0  \n",
       "3  0.369345  23.5603  12.7074  11.42447 -30.470246  18.8329       0  \n",
       "4  0.543360  35.4940  15.9546   8.87237 -16.378376  24.9171       0  "
      ]
     },
     "execution_count": 894,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Untuk mengubah variabel \"Target\" dari kategorik menjadi numerik\n",
    "spine[\"Target\"].replace([\"Abnormal\", \"Normal\"], [0, 1], inplace = True)\n",
    "spine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada variabel \"Target\", kelas \"Abnormal\" diubah menjadi 0 dan kelas \"Normal\" diubah menjadi 1. Hal ini dilakukan untuk memudahkan dalam memproses data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Coefficient Correlation'}>"
      ]
     },
     "execution_count": 895,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Untuk melihat coefficient correlation dari variabel independen terhadap variabel dependen\n",
    "spine_corr = spine.corr()[[\"Target\"]].sort_values(by = [\"Target\"], ascending = False)\n",
    "\n",
    "plt.figure(figsize = (4,7))\n",
    "plt.title(\"Coefficient Correlation\")\n",
    "\n",
    "sns.heatmap(spine_corr, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari plot tersebut, terlihat bahwa variabel \"Col5\" memiliki korelasi positif yang cukup kuat terhadap variabel \"Target\". Artinya, jika nilai variabel \"Col5\" meningkat, maka nilai variabel \"Target\" juga ikut meningkat.\n",
    "\n",
    "Sementara itu, variabel \"Col6\" memiliki korelasi negatif yang cukup kuat terhadap variabel \"Target\". Artinya, jika nilai variabel \"Col6\" meningkat, maka nilai variabel \"Target\" akan menurun.\n",
    "\n",
    "Selain itu, variabel \"Col12\", \"Col9\", \"Col8\", \"Col11\", dan \"Col7\" memiliki nilai korelasi mendekati 0, yang menunjukkan bahwa variabel tersebut tidak memiliki pengaruh yang signifikan terhadap variabel \"Target\". Hal ini bisa dijadikan sebagai pertimbangan untuk menghapus variabel-variabel tersebut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secara keseluruhan, beberapa hal yang ditemukan dari dataset ini setelah melakukan EDA adalah:\n",
    "1.   **Data imbalanced**. Hal ini bisa diatasi dengan cara teknik resampling, seperti oversampling atau undersampling. Oversampling adalah teknik untuk menambah data pada kelas minoritas, dalam data ini adalah pada kelas \"Normal\". Sedangkan, undersampling adalah teknik untuk mengurangi data pada kelas mayoritas, dalam data ini adalah pada kelas \"Abnormal\". Oversampling bisa digunakan pada kasus ini karena jumlah datanya tidak banyak, sehingga oversampling lebih disarankan daripada undersampling.\n",
    "2.   **Menghapus variabel \"Unnamed: 0\"**. Variabel \"Unnamed: 0\" dihapus karena merupakan sebuah ID unik yang tidak terkait dengan variabel target secara langsung\n",
    "3.   **Mengganti nama variabel \"Class_att\" menjadi \"Target**\". Variabel \"Class_att\" diganti nama menjadi \"Target\" untuk mempermudah dalam memproses data.\n",
    "4.   **Melakukan feature engineering pada variabel \"Target\"**. Melakukan label encoding pada variabel \"Target\" untuk mengubah data dari kategorik menjadi numerik.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library untuk melakukan split terhadap dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk memisahkan variable prediktor dan target\n",
    "prediktor = spine.drop([\"Target\"], axis = 1)\n",
    "target = spine[\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk membagi dataset menjadi train data, test data, dan validation data\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(prediktor, target, train_size = 0.8, random_state = 42)\n",
    "x_val, x_test, y_val, y_test  = train_test_split(x_temp, y_temp, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data      (x, y): ( 248 , 248 )\n",
      "Test data       (x, y): ( 31 , 31 )\n",
      "Validation data (x, y): ( 31 , 31 )\n"
     ]
    }
   ],
   "source": [
    "# Untuk melihat banyaknya train data, test data, dan validation data\n",
    "print(\"Train data      (x, y): (\", len(x_train), \",\", len(y_train), \")\")\n",
    "print(\"Test data       (x, y): (\", len(x_test), \",\", len(y_test), \")\")\n",
    "print(\"Validation data (x, y): (\", len(x_val), \",\", len(y_val), \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output tersebut, terlihat bahwa dari 310 data berhasil dibagi menjadi 80% train yaitu sebanyak 248 data, 10% test yaitu sebanyak 31 data, and 10% validation yaitu sebanyak 31 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library untuk melakukan SMOTE pada teknik oversampling\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk menambahkan data menggunakan SMOTE pada data training\n",
    "smote = SMOTE(random_state = 42)\n",
    "x_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data (before SMOTE) (Target):\n",
      "0    166\n",
      "1     82\n",
      "Name: Target, dtype: int64\n",
      "\n",
      "Train data (after SMOTE) (Target):\n",
      "0    166\n",
      "1    166\n",
      "Name: Target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Untuk membandingkan banyaknya train data sebelum dan sesudah dilakukan SMOTE\n",
    "print(\"Train data (before SMOTE) (Target):\")\n",
    "print(y_train.value_counts())\n",
    "print()\n",
    "print(\"Train data (after SMOTE) (Target):\")\n",
    "print(y_train_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk mengatasi masalah imbalanced pada data ini, saya menggunakan metode oversampling SMOTE. Synthetic Minority Oversampling Technique atau SMOTE adalah suatu proses data augmentasi untuk kelas minoritas dengan cara membuat sampel-sampel sintetis baru untuk kelas minoritas. Metode ini akan mengambil contoh case minoritas dari data input yang mendekati feature space, lalu menarik garis antara contoh dalam feature space tersebut dan membuat sampel baru di sepanjang garis tersebut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library untuk membuat architecture\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk membuat architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Untuk membuat input layer\n",
    "model.add(Dense(units = 12, activation = 'sigmoid', input_shape = (x_train.shape[1],)))\n",
    "\n",
    "# Untuk membuat hidden layer\n",
    "model.add(Dense(units = 512, activation = 'sigmoid'))\n",
    "model.add(Dense(units = 256, activation = 'sigmoid'))\n",
    "model.add(Dense(units = 128, activation = 'sigmoid'))\n",
    "\n",
    "# Untuk membuat output layer\n",
    "model.add(Dense(units = 2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada input layer, model menggunakan 12 unit neuron sesuai dengan jumlah fitur atau variabel pada dataset dengan activation function sigmoid.\n",
    "\n",
    "Pada hidden layer, model atau layer pertama menggunakan 512 unit neuron, kemudian layer kedua menggunakan 256 unit neuron, dan layer terakhir menggunakan 128 unit neuron dengan activation function sigmoid sesuai dengan ketentuan pada soal.\n",
    "\n",
    "Pada output layer, model menggunakan 2 unit neuron dengan activation function softmax sesuai dengan ketentuan pada soal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_676 (Dense)           (None, 12)                156       \n",
      "                                                                 \n",
      " dense_677 (Dense)           (None, 512)               6656      \n",
      "                                                                 \n",
      " dense_678 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_679 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_680 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 171294 (669.12 KB)\n",
      "Trainable params: 171294 (669.12 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Untuk menampilkan summary model atau arsitektur yang telah dibuat\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari architecture di atas, terdapat 5 model fully connected layer. Total params diperolah dari jumlah parameter dari masing-masing model. Nilai non-trainable params nya 0 menandakan bahwa selama pelatihan tidak ada model atau layer yang difreeze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk mengcompile model\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter yang digunakan pada saat mengompile model antara lain adalah optimizer \"Adam\" karena memberikan performa yang lebih baik, kemudian loss \"SparseCategoricalCrossentropy\" karena ada dua kelas pada variabel \"Target\" dimana labelnya bukan merupakan One Hot dan mengikuti activation function softmax, serta yang terakhir metrics \"Accuracy\" untuk menampilkan accuracy yang diperoleh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 2s 44ms/step - loss: 0.6832 - accuracy: 0.6613 - val_loss: 0.6051 - val_accuracy: 0.7097\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6489 - accuracy: 0.6694 - val_loss: 0.6031 - val_accuracy: 0.7097\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6584 - accuracy: 0.6694 - val_loss: 0.6039 - val_accuracy: 0.7097\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6343 - accuracy: 0.6694 - val_loss: 0.6000 - val_accuracy: 0.7097\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6390 - accuracy: 0.6694 - val_loss: 0.6039 - val_accuracy: 0.7097\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6347 - accuracy: 0.6694 - val_loss: 0.6001 - val_accuracy: 0.7097\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6313 - accuracy: 0.6694 - val_loss: 0.5994 - val_accuracy: 0.7097\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6302 - accuracy: 0.6694 - val_loss: 0.6004 - val_accuracy: 0.7097\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6274 - accuracy: 0.6694 - val_loss: 0.5995 - val_accuracy: 0.7097\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6276 - accuracy: 0.6694 - val_loss: 0.5962 - val_accuracy: 0.7097\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6223 - accuracy: 0.6694 - val_loss: 0.5865 - val_accuracy: 0.7097\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6187 - accuracy: 0.6694 - val_loss: 0.5821 - val_accuracy: 0.7097\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6125 - accuracy: 0.6694 - val_loss: 0.5627 - val_accuracy: 0.7097\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5958 - accuracy: 0.6694 - val_loss: 0.5740 - val_accuracy: 0.7097\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6142 - accuracy: 0.6573 - val_loss: 0.5460 - val_accuracy: 0.7097\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5589 - accuracy: 0.6653 - val_loss: 0.5064 - val_accuracy: 0.7742\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5216 - accuracy: 0.6935 - val_loss: 0.4602 - val_accuracy: 0.7097\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4857 - accuracy: 0.7419 - val_loss: 0.4313 - val_accuracy: 0.7419\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4439 - accuracy: 0.7823 - val_loss: 0.3970 - val_accuracy: 0.7742\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4294 - accuracy: 0.8065 - val_loss: 0.4174 - val_accuracy: 0.7742\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4343 - accuracy: 0.7742 - val_loss: 0.3808 - val_accuracy: 0.7742\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4177 - accuracy: 0.8024 - val_loss: 0.3583 - val_accuracy: 0.7742\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4190 - accuracy: 0.7903 - val_loss: 0.3552 - val_accuracy: 0.7742\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4104 - accuracy: 0.8065 - val_loss: 0.3528 - val_accuracy: 0.7742\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4099 - accuracy: 0.7581 - val_loss: 0.3522 - val_accuracy: 0.8065\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4441 - accuracy: 0.7339 - val_loss: 0.4074 - val_accuracy: 0.7742\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3919 - accuracy: 0.8024 - val_loss: 0.3587 - val_accuracy: 0.8387\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4040 - accuracy: 0.8145 - val_loss: 0.3509 - val_accuracy: 0.7742\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3992 - accuracy: 0.8024 - val_loss: 0.3583 - val_accuracy: 0.7742\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3983 - accuracy: 0.8185 - val_loss: 0.3452 - val_accuracy: 0.7742\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3811 - accuracy: 0.8065 - val_loss: 0.3441 - val_accuracy: 0.8065\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3868 - accuracy: 0.8105 - val_loss: 0.3421 - val_accuracy: 0.7742\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3944 - accuracy: 0.7984 - val_loss: 0.3386 - val_accuracy: 0.7742\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3907 - accuracy: 0.8347 - val_loss: 0.3367 - val_accuracy: 0.7742\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4280 - accuracy: 0.7823 - val_loss: 0.3788 - val_accuracy: 0.8387\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4193 - accuracy: 0.7621 - val_loss: 0.3270 - val_accuracy: 0.8387\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3698 - accuracy: 0.8185 - val_loss: 0.3651 - val_accuracy: 0.7742\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3663 - accuracy: 0.8105 - val_loss: 0.3340 - val_accuracy: 0.7742\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3629 - accuracy: 0.8226 - val_loss: 0.3459 - val_accuracy: 0.7742\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3635 - accuracy: 0.8226 - val_loss: 0.3375 - val_accuracy: 0.7742\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3555 - accuracy: 0.8185 - val_loss: 0.3288 - val_accuracy: 0.7742\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3489 - accuracy: 0.8306 - val_loss: 0.3505 - val_accuracy: 0.8065\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3488 - accuracy: 0.8347 - val_loss: 0.3169 - val_accuracy: 0.7742\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3513 - accuracy: 0.8226 - val_loss: 0.3562 - val_accuracy: 0.7742\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3447 - accuracy: 0.8266 - val_loss: 0.3273 - val_accuracy: 0.7419\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3420 - accuracy: 0.8266 - val_loss: 0.3311 - val_accuracy: 0.7742\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3377 - accuracy: 0.8266 - val_loss: 0.3476 - val_accuracy: 0.7742\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3339 - accuracy: 0.8266 - val_loss: 0.3251 - val_accuracy: 0.7742\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3312 - accuracy: 0.8266 - val_loss: 0.3681 - val_accuracy: 0.8387\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3558 - accuracy: 0.8387 - val_loss: 0.3239 - val_accuracy: 0.7742\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    epochs = 50,\n",
    "                    batch_size = 32,\n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk menyimpan history dari training model yang sebelumnya telah dilakukan\n",
    "hist_dict = history.history\n",
    "train_loss = hist_dict[\"loss\"]\n",
    "val_loss = hist_dict[\"val_loss\"]\n",
    "train_acc = hist_dict[\"accuracy\"]\n",
    "val_acc = hist_dict[\"val_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk menyimpan range epoch dari training model sebelumnya\n",
    "epochs_loss = range(1, len(train_loss)+1)\n",
    "epochs_acc = range(1, len(train_acc)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Untuk membuat plot training dan validation loss serta training dan validation accuracy\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "axs[0].plot(epochs_loss, train_loss, 'b-', label=\"Training Loss\")\n",
    "axs[0].plot(epochs_loss, val_loss, 'r-', label=\"Validation Loss\")\n",
    "axs[0].set_title(\"Training and Validation Loss\")\n",
    "axs[0].set_xlabel(\"Epochs\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(epochs_acc, train_acc, 'b-', label=\"Training Accuracy\")\n",
    "axs[1].plot(epochs_acc, val_acc, 'r-', label=\"Validation Accuracy\")\n",
    "axs[1].set_title(\"Training and Validation Accuracy\")\n",
    "axs[1].set_xlabel(\"Epochs\")\n",
    "axs[1].set_ylabel(\"Accuracy\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah ditrain sebanyak 50 epoch dan menggunakan 32 sampel data setiap batchnya, diperoleh hasil train accuracy nya sebesar 0.8387 dan val accuracy nya sebesar 0.7742. Sementara itu, diperoleh hasil train loss nya sebesar 0.3558 dan val loss nya sebesar 0.3239.\n",
    "\n",
    "Model ini bisa dikatakan kurang baik dan ada indikasi underfitting karena nilai train loss nya berada di atas nilai val loss. Artinya, model masih kurang baik dalam memahami pola dalam data baru.\n",
    "\n",
    "Selain itu, nilai train accuracy juga berada di atas nilai val accuracy. Artinya, model masih kurang baik dalam memprediksi data, baik dari data training maupun data baru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5199 - accuracy: 0.6774\n",
      "Model\n",
      "Test loss     : 0.5198559761047363\n",
      "Test accuracy : 0.6774193644523621\n"
     ]
    }
   ],
   "source": [
    "# Untuk melakukan evaluasi model menggunakan data validation dan training model sebelumnya\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Model\")\n",
    "print(f\"Test loss     : \" + str(test_loss))\n",
    "print(f\"Test accuracy : \" + str(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah mencoba memprediksi menggunakan model dan data testing, diperoleh nilai test accuracy nya sebesar 0.68 dan nilai test loss nya sebesar 0.52. Hal ini berarti model masih kurang baik dalam memprediksi dan harus ditingkatkan lagi performanya dalam memprediksi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percobaan ke-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk membuat architecture\n",
    "model1 = Sequential()\n",
    "\n",
    "# Untuk membuat input layer\n",
    "model1.add(Dense(units = 12, activation = 'relu', input_shape = (x_train.shape[1],)))\n",
    "\n",
    "# Untuk membuat hidden layer\n",
    "model1.add(Dense(units = 512, activation = 'relu'))\n",
    "model1.add(Dense(units = 256, activation = 'relu'))\n",
    "model1.add(Dense(units = 128, activation = 'relu'))\n",
    "model1.add(Dense(units = 64, activation = 'relu'))\n",
    "model1.add(Dense(units = 32, activation = 'relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "\n",
    "# Untuk membuat output layer\n",
    "model1.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada input layer, model menggunakan 12 unit neuron sesuai dengan jumlah fitur atau variabel pada dataset dengan activation function ReLU.\n",
    "\n",
    "Pada hidden layer, model atau layer pertama menggunakan 512 unit neuron, kemudian layer kedua menggunakan 256 unit neuron, dan layer berikutnya menggunakan n/2 unit neuron hingga layer terakhir menggunakan 32 unit neuron dengan activation function ReLU.\n",
    "\n",
    "Alasan saya memakai activation function relu pada input dan hidden layer adalah karena ReLU memiliki performa yang lebih cepat daripada sigmoid.\n",
    "\n",
    "Pada output layer, model menggunakan 1 unit neuron dengan activation function sigmoid sesuai dengan task dari dataset ini, yaitu binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library untuk menggunakan optimizer Adam\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk mengatur parameter pada optimizer Adam\n",
    "optimizer = Adam(learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disini saya menggunakan optimizer Adam yang mana saya sudah mencoba untuk mengganti learning rate nya berkali-kali. Namun, diperoleh hasil yang paling baik yang menggunakan nilai defaultnya,  yaitu 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk mengcompile model\n",
    "model1.compile(optimizer = optimizer,\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter yang digunakan pada saat mengompile model1 antara lain adalah optimizer \"Adam\" dengan learning rate 0.001 karena memberikan performa yang lebih baik, kemudian loss \"BinaryCrossentropy\" karena ada dua kelas pada variabel \"Target\" dimana labelnya bukan merupakan One Hot dan mengikuti activation function sigmoid, serta yang terakhir metrics \"Accuracy\" untuk menampilkan accuracy yang diperoleh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 3s 155ms/step - loss: 1.1703 - accuracy: 0.5766 - val_loss: 0.5673 - val_accuracy: 0.7097\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6781 - accuracy: 0.6250 - val_loss: 0.4741 - val_accuracy: 0.7742\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6026 - accuracy: 0.7016 - val_loss: 0.6246 - val_accuracy: 0.7097\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6400 - accuracy: 0.6694 - val_loss: 0.5290 - val_accuracy: 0.7097\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5731 - accuracy: 0.6815 - val_loss: 0.4501 - val_accuracy: 0.6452\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5411 - accuracy: 0.7218 - val_loss: 0.4751 - val_accuracy: 0.6452\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5114 - accuracy: 0.6734 - val_loss: 0.4086 - val_accuracy: 0.7419\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5066 - accuracy: 0.7177 - val_loss: 0.4466 - val_accuracy: 0.7097\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5069 - accuracy: 0.6653 - val_loss: 0.4099 - val_accuracy: 0.7097\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4801 - accuracy: 0.6613 - val_loss: 0.4314 - val_accuracy: 0.7097\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4793 - accuracy: 0.6734 - val_loss: 0.3844 - val_accuracy: 0.7742\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4459 - accuracy: 0.7500 - val_loss: 0.4036 - val_accuracy: 0.7097\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4447 - accuracy: 0.7661 - val_loss: 0.3360 - val_accuracy: 0.7742\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4996 - accuracy: 0.7056 - val_loss: 0.3696 - val_accuracy: 0.7419\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4472 - accuracy: 0.7298 - val_loss: 0.3490 - val_accuracy: 0.7742\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4475 - accuracy: 0.7137 - val_loss: 0.3526 - val_accuracy: 0.8387\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4398 - accuracy: 0.7056 - val_loss: 0.3422 - val_accuracy: 0.8065\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4443 - accuracy: 0.6895 - val_loss: 0.3839 - val_accuracy: 0.7097\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4316 - accuracy: 0.6976 - val_loss: 0.3430 - val_accuracy: 0.8387\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4207 - accuracy: 0.7056 - val_loss: 0.3239 - val_accuracy: 0.8387\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3910 - accuracy: 0.7500 - val_loss: 0.3051 - val_accuracy: 0.8387\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3961 - accuracy: 0.8105 - val_loss: 0.2733 - val_accuracy: 0.9032\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4164 - accuracy: 0.7661 - val_loss: 0.2653 - val_accuracy: 0.9032\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4110 - accuracy: 0.7621 - val_loss: 0.3216 - val_accuracy: 0.8065\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4059 - accuracy: 0.7782 - val_loss: 0.2923 - val_accuracy: 0.8387\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3712 - accuracy: 0.7863 - val_loss: 0.3081 - val_accuracy: 0.8065\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3792 - accuracy: 0.7702 - val_loss: 0.2890 - val_accuracy: 0.8387\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3710 - accuracy: 0.8065 - val_loss: 0.2775 - val_accuracy: 0.8387\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3685 - accuracy: 0.8065 - val_loss: 0.2654 - val_accuracy: 0.8710\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3928 - accuracy: 0.8024 - val_loss: 0.3032 - val_accuracy: 0.9032\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3976 - accuracy: 0.7460 - val_loss: 0.3183 - val_accuracy: 0.7419\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3852 - accuracy: 0.7903 - val_loss: 0.2733 - val_accuracy: 0.8065\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3716 - accuracy: 0.8024 - val_loss: 0.2885 - val_accuracy: 0.8065\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3899 - accuracy: 0.8105 - val_loss: 0.3004 - val_accuracy: 0.8387\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3555 - accuracy: 0.8347 - val_loss: 0.2564 - val_accuracy: 0.8387\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3498 - accuracy: 0.8065 - val_loss: 0.2867 - val_accuracy: 0.8065\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3400 - accuracy: 0.8306 - val_loss: 0.2564 - val_accuracy: 0.8387\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3288 - accuracy: 0.8024 - val_loss: 0.2545 - val_accuracy: 0.8387\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3337 - accuracy: 0.8145 - val_loss: 0.2442 - val_accuracy: 0.9032\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3214 - accuracy: 0.8548 - val_loss: 0.2928 - val_accuracy: 0.8387\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3216 - accuracy: 0.8669 - val_loss: 0.2600 - val_accuracy: 0.8710\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3153 - accuracy: 0.8266 - val_loss: 0.2919 - val_accuracy: 0.8710\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3105 - accuracy: 0.8427 - val_loss: 0.2850 - val_accuracy: 0.8710\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3079 - accuracy: 0.8306 - val_loss: 0.2752 - val_accuracy: 0.8387\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2759 - accuracy: 0.8629 - val_loss: 0.2812 - val_accuracy: 0.9032\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2917 - accuracy: 0.8468 - val_loss: 0.2887 - val_accuracy: 0.8710\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.3194 - accuracy: 0.8468 - val_loss: 0.3403 - val_accuracy: 0.8065\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3150 - accuracy: 0.8427 - val_loss: 0.3571 - val_accuracy: 0.8710\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3222 - accuracy: 0.8226 - val_loss: 0.3157 - val_accuracy: 0.8065\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3137 - accuracy: 0.8306 - val_loss: 0.3499 - val_accuracy: 0.8710\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(x_train, y_train,\n",
    "                    epochs = 50,\n",
    "                    batch_size = 64,\n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah ditrain sebanyak 50 epoch dan menggunakan 64 sampel data setiap batchnya, diperoleh hasil train accuracy nya sebesar 0.8306 dan val accuracy nya sebesar 0.8710. Sementara itu, diperoleh hasil train loss nya sebesar 0.3137 dan val loss nya sebesar 0.3499.\n",
    "\n",
    "Kedua nilai loss yang diperoleh memang memiliki perbedaan yang tidak terlalu signifikan, begitupula dengan kedua nilai accuracy. Namun, jika nilai val accuracy nya terus meningkat dan train accuracy nya tetap atau menurun, model dapat menjadi overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3935 - accuracy: 0.7742\n",
      "Model 1\n",
      "Test loss     : 0.39353758096694946\n",
      "Test accuracy : 0.774193525314331\n"
     ]
    }
   ],
   "source": [
    "# Untuk melakukan evaluasi model menggunakan data validation dan training model sebelumnya\n",
    "test_loss1, test_accuracy1 = model1.evaluate(x_test, y_test)\n",
    "print(\"Model 1\")\n",
    "print(f\"Test loss     : \" + str(test_loss1))\n",
    "print(f\"Test accuracy : \" + str(test_accuracy1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah mencoba memprediksi menggunakan model1 dan data testing, diperoleh nilai test accuracy nya sebesar 0.77 dan nilai test loss nya sebesar 0.39. Hal ini berarti model cukup baik dalam memprediksi, tetapi masih bisa ditingkatkan lagi performanya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percobaan ke-2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk membuat architecture\n",
    "model2 = Sequential()\n",
    "\n",
    "# Untuk membuat input layer\n",
    "model2.add(Dense(units = 12, activation = 'relu', input_shape = (x_train.shape[1],)))\n",
    "\n",
    "# Untuk membuat hidden layer\n",
    "model2.add(Dense(units = 512, activation = 'relu'))\n",
    "model2.add(Dense(units = 256, activation = 'relu'))\n",
    "model2.add(Dense(units = 128, activation = 'relu'))\n",
    "model2.add(Dense(units = 64, activation = 'relu'))\n",
    "model2.add(Dense(units = 32, activation = 'relu'))\n",
    "model2.add(Dense(units = 16, activation = 'relu'))\n",
    "\n",
    "# Untuk membuat output layer\n",
    "model2.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada input layer, model menggunakan 12 unit neuron sesuai dengan jumlah fitur atau variabel pada dataset dengan activation function ReLU.\n",
    "\n",
    "Pada hidden layer, model atau layer pertama menggunakan 512 unit neuron, kemudian layer kedua menggunakan 256 unit neuron, dan layer berikutnya menggunakan n/2 unit neuron hingga layer terakhir menggunakan 16 unit neuron dengan activation function ReLU.\n",
    "\n",
    "Alasan saya memakai activation function relu pada input dan hidden layer adalah karena ReLU memiliki performa yang lebih cepat daripada sigmoid.\n",
    "\n",
    "Perbedaan model1 dan model2 adalah saya menambahkan 1 hidden layer dengan jumlah neuron 16 unit.\n",
    "\n",
    "Pada output layer, model menggunakan 1 unit neuron dengan activation function sigmoid sesuai dengan task dari dataset ini, yaitu binary classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk mengatur parameter pada optimizer RMSProp\n",
    "optimizer = RMSprop(learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disini saya menggunakan optimizer RMSprop yang mana saya sudah mencoba untuk mengganti learning rate nya berkali-kali. Namun, diperoleh hasil yang paling baik yang menggunakan nilai defaultnya, yaitu 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk mengcompile model\n",
    "model2.compile(optimizer = optimizer,\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter yang digunakan pada saat mengompile model2 antara lain adalah optimizer \"RMSprop\" dengan learning rate 0.001 untuk mencoba memberikan gradient yang lebih baik selama pelatihan, kemudian loss \"BinaryCrossentropy\" karena ada dua kelas pada variabel \"Target\" dimana labelnya bukan merupakan One Hot dan mengikuti activation function sigmoid, serta yang terakhir metrics \"Accuracy\" untuk menampilkan accuracy yang diperoleh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk menginisialisasi callback\n",
    "callback_es = EarlyStopping(monitor = 'val_loss',\n",
    "                         patience = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model akan melakukan early stopping apabila nilai val loss tidak mengalami peningkatan setelah 5 epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 33ms/step - loss: 1.4157 - accuracy: 0.5806 - val_loss: 0.5457 - val_accuracy: 0.7097\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5538 - accuracy: 0.6935 - val_loss: 0.4570 - val_accuracy: 0.8065\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5565 - accuracy: 0.6411 - val_loss: 0.8382 - val_accuracy: 0.7097\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6149 - accuracy: 0.6452 - val_loss: 0.5122 - val_accuracy: 0.7097\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4639 - accuracy: 0.7097 - val_loss: 0.6849 - val_accuracy: 0.6774\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4687 - accuracy: 0.7702 - val_loss: 0.5382 - val_accuracy: 0.7097\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5058 - accuracy: 0.7540 - val_loss: 0.5243 - val_accuracy: 0.7742\n"
     ]
    }
   ],
   "source": [
    "# Untuk melakukan training model\n",
    "history2 = model2.fit(x_train, y_train,\n",
    "                    epochs = 50,\n",
    "                    batch_size = 32,\n",
    "                    callbacks = callback_es,\n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah ditrain sebanyak 50 epoch dan menggunakan 32 sampel data setiap batchnya, diperoleh hasil train accuracy nya sebesar 0.7540 dan val accuracy nya sebesar 0.7742. Sementara itu, diperoleh hasil train loss nya sebesar 0.5058 dan val loss nya sebesar 0.5243.\n",
    "\n",
    "Kedua nilai loss yang diperoleh memang memiliki perbedaan yang tidak terlalu signifikan, begitupula dengan kedua nilai accuracy. Model ini bisa dikatakan good fit, tetapi masih bida ditingkatkan lagi performa nya dengan menurunkan nilai loss dan meningkatkan nilai accuracy nya.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6108 - accuracy: 0.7742\n",
      "Model 2\n",
      "Test loss     : 0.6108383536338806\n",
      "Test accuracy : 0.774193525314331\n"
     ]
    }
   ],
   "source": [
    "# Untuk melakukan evaluasi model menggunakan data validation dan training model sebelumnya\n",
    "test_loss2, test_accuracy2 = model2.evaluate(x_test, y_test)\n",
    "print(\"Model 2\")\n",
    "print(f\"Test loss     : \" + str(test_loss2))\n",
    "print(f\"Test accuracy : \" + str(test_accuracy2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah mencoba memprediksi menggunakan model2 dan data testing, diperoleh nilai test accuracy nya sebesar 0.77 dan nilai test loss nya sebesar 0.61. Hal ini berarti model masih kurang baik dalam memprediksi dan harus ditingkatkan lagi performanya dalam memprediksi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percobaan ke-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk membuat architecture\n",
    "model3 = Sequential()\n",
    "\n",
    "# Untuk membuat input layer\n",
    "model3.add(Dense(units = 12, activation = 'relu', input_shape = (x_train.shape[1],)))\n",
    "\n",
    "# Untuk membuat hidden layer\n",
    "model3.add(Dense(units = 1024, activation = 'relu'))\n",
    "model3.add(Dense(units = 512, activation = 'relu'))\n",
    "model3.add(Dense(units = 256, activation = 'relu'))\n",
    "model3.add(Dense(units = 128, activation = 'relu'))\n",
    "model3.add(Dense(units = 64, activation = 'relu'))\n",
    "\n",
    "# Untuk membuat output layer\n",
    "model3.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada input layer, model menggunakan 12 unit neuron sesuai dengan jumlah fitur atau variabel pada dataset dengan activation function ReLU.\n",
    "\n",
    "Pada hidden layer, model atau layer pertama menggunakan 1024 unit neuron, kemudian layer kedua menggunakan 256 unit neuron, dan layer berikutnya menggunakan n/2 unit neuron hingga layer terakhir menggunakan 64 unit neuron dengan activation function ReLU.\n",
    "\n",
    "Alasan saya memakai activation function relu pada input dan hidden layer adalah karena ReLU memiliki performa yang lebih cepat daripada sigmoid.\n",
    "\n",
    "Perbedaan model ini dengan model sebelumnya adalah saya menambahkan 1 hidden layer dengan jumlah neuron 1024 unit.\n",
    "\n",
    "Pada output layer, model menggunakan 1 unit neuron dengan activation function sigmoid sesuai dengan task dari dataset ini, yaitu binary classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk mengatur parameter pada optimizer Adam\n",
    "optimizer = Adam(learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disini saya menggunakan optimizer Adam yang mana saya sudah mencoba untuk mengganti learning rate nya berkali-kali. Namun, diperoleh hasil yang paling baik yang menggunakan nilai defaultnya, yaitu 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk mengcompile model\n",
    "model3.compile(optimizer = optimizer,\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter yang digunakan pada saat mengompile model antara lain adalah optimizer \"Adam\" karena memberikan performa yang lebih baik, kemudian loss \"BinaryCrossentropy\" karena ada dua kelas pada variabel \"Target\" dimana labelnya bukan merupakan One Hot dan mengikuti activation function softmax, serta yang terakhir metrics \"Accuracy\" untuk menampilkan accuracy yang diperoleh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library untuk menggunakan callback pada saat pelatihan model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk menginisialisasi callback\n",
    "callback_lr = ReduceLROnPlateau(monitor ='val_loss',\n",
    "                                factor = 0.2,\n",
    "                                patience = 3,\n",
    "                                min_lr = 1e-6,\n",
    "                                verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model akan melakukan pengurangan nilai learning rate sebesar learning rate dikalikan 0.2 apabila nilai val loss tidak berubah setelah 3 epoch. Minimum nilai learning rate yang ditentukan adalah sebesar 1^e-6, jika learning rate telah sampai pada batas minimum maka learning rate tidak akan dikurangi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 2s 49ms/step - loss: 0.9408 - accuracy: 0.6008 - val_loss: 0.5034 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.4536 - accuracy: 0.7702 - val_loss: 0.3462 - val_accuracy: 0.8387 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5322 - accuracy: 0.7258 - val_loss: 0.3698 - val_accuracy: 0.8387 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.5139 - accuracy: 0.7137 - val_loss: 0.3686 - val_accuracy: 0.8065 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.4823 - accuracy: 0.7455\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4696 - accuracy: 0.7581 - val_loss: 0.4285 - val_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4547 - accuracy: 0.7702 - val_loss: 0.3479 - val_accuracy: 0.7742 - lr: 2.0000e-04\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4069 - accuracy: 0.7540 - val_loss: 0.3542 - val_accuracy: 0.7742 - lr: 2.0000e-04\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3999 - accuracy: 0.7702 - val_loss: 0.3459 - val_accuracy: 0.8387 - lr: 2.0000e-04\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.3958 - accuracy: 0.7984 - val_loss: 0.3443 - val_accuracy: 0.8065 - lr: 2.0000e-04\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3919 - accuracy: 0.7944 - val_loss: 0.3485 - val_accuracy: 0.8065 - lr: 2.0000e-04\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3939 - accuracy: 0.7863 - val_loss: 0.3528 - val_accuracy: 0.8065 - lr: 2.0000e-04\n",
      "Epoch 12/50\n",
      "5/8 [=================>............] - ETA: 0s - loss: 0.4071 - accuracy: 0.7625\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.3917 - accuracy: 0.7863 - val_loss: 0.3562 - val_accuracy: 0.7742 - lr: 2.0000e-04\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3888 - accuracy: 0.7823 - val_loss: 0.3545 - val_accuracy: 0.7742 - lr: 4.0000e-05\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3856 - accuracy: 0.7944 - val_loss: 0.3548 - val_accuracy: 0.8065 - lr: 4.0000e-05\n",
      "Epoch 15/50\n",
      "5/8 [=================>............] - ETA: 0s - loss: 0.3729 - accuracy: 0.7875\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.3852 - accuracy: 0.7863 - val_loss: 0.3552 - val_accuracy: 0.8065 - lr: 4.0000e-05\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.3846 - accuracy: 0.7863 - val_loss: 0.3551 - val_accuracy: 0.8065 - lr: 8.0000e-06\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3846 - accuracy: 0.7863 - val_loss: 0.3549 - val_accuracy: 0.8065 - lr: 8.0000e-06\n",
      "Epoch 18/50\n",
      "5/8 [=================>............] - ETA: 0s - loss: 0.3741 - accuracy: 0.8062\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3843 - accuracy: 0.7903 - val_loss: 0.3550 - val_accuracy: 0.8065 - lr: 8.0000e-06\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.3842 - accuracy: 0.7903 - val_loss: 0.3549 - val_accuracy: 0.8065 - lr: 1.6000e-06\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.3842 - accuracy: 0.7944 - val_loss: 0.3549 - val_accuracy: 0.8065 - lr: 1.6000e-06\n",
      "Epoch 21/50\n",
      "5/8 [=================>............] - ETA: 0s - loss: 0.3765 - accuracy: 0.7750\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.3842 - accuracy: 0.7944 - val_loss: 0.3549 - val_accuracy: 0.8065 - lr: 1.6000e-06\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3842 - accuracy: 0.7944 - val_loss: 0.3549 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3842 - accuracy: 0.7903 - val_loss: 0.3549 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3841 - accuracy: 0.7944 - val_loss: 0.3549 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3841 - accuracy: 0.7944 - val_loss: 0.3549 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3841 - accuracy: 0.7903 - val_loss: 0.3549 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.3842 - accuracy: 0.7903 - val_loss: 0.3549 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3841 - accuracy: 0.7903 - val_loss: 0.3549 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3841 - accuracy: 0.7944 - val_loss: 0.3549 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3841 - accuracy: 0.7944 - val_loss: 0.3550 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3841 - accuracy: 0.7903 - val_loss: 0.3550 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3841 - accuracy: 0.7903 - val_loss: 0.3550 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3841 - accuracy: 0.7944 - val_loss: 0.3550 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3841 - accuracy: 0.7903 - val_loss: 0.3550 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.3841 - accuracy: 0.7903 - val_loss: 0.3550 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3841 - accuracy: 0.7903 - val_loss: 0.3550 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.3840 - accuracy: 0.7944 - val_loss: 0.3550 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3840 - accuracy: 0.7944 - val_loss: 0.3550 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.3840 - accuracy: 0.7944 - val_loss: 0.3550 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3840 - accuracy: 0.7944 - val_loss: 0.3550 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3840 - accuracy: 0.7944 - val_loss: 0.3550 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.3839 - accuracy: 0.7944 - val_loss: 0.3550 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3840 - accuracy: 0.7903 - val_loss: 0.3550 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3839 - accuracy: 0.7944 - val_loss: 0.3550 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.3839 - accuracy: 0.7944 - val_loss: 0.3550 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3839 - accuracy: 0.7944 - val_loss: 0.3550 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.3839 - accuracy: 0.7944 - val_loss: 0.3551 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.3839 - accuracy: 0.7944 - val_loss: 0.3551 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.3839 - accuracy: 0.7944 - val_loss: 0.3551 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3839 - accuracy: 0.7944 - val_loss: 0.3551 - val_accuracy: 0.8065 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "# Untuk melakukan training model\n",
    "history3 = model3.fit(x_train, y_train,\n",
    "                    epochs = 50,\n",
    "                    batch_size = 32,\n",
    "                    callbacks = callback_lr,\n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah ditrain sebanyak 50 epoch dan menggunakan 32 sampel data setiap batchnya, diperoleh hasil train accuracy nya sebesar 0.7944 dan val accuracy nya sebesar 0.8065. Sementara itu, diperoleh hasil train loss nya sebesar 0.3829 dan val loss nya sebesar 0.3551.\n",
    "\n",
    "Kedua nilai loss yang diperoleh memang memiliki perbedaan yang tidak terlalu signifikan, begitupula dengan kedua nilai accuracy. Namun, nilai train loss lebih besar daripada val loss sehingga terdapat indikasi underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4206 - accuracy: 0.7419\n",
      "Model 3\n",
      "Test loss     : 0.42064014077186584\n",
      "Test accuracy : 0.7419354915618896\n"
     ]
    }
   ],
   "source": [
    "# Untuk melakukan evaluasi model menggunakan data validation dan training model sebelumnya\n",
    "test_loss3, test_accuracy3 = model3.evaluate(x_test, y_test)\n",
    "print(\"Model 3\")\n",
    "print(f\"Test loss     : \" + str(test_loss3))\n",
    "print(f\"Test accuracy : \" + str(test_accuracy3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah mencoba memprediksi menggunakan model3 dan data testing, diperoleh nilai test accuracy nya sebesar 0.74 dan nilai test loss nya sebesar 0.42. Hal ini berarti model cukup baik dalam memprediksi, tetapi masih bisa ditingkatkan lagi performanya dalam memprediksi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percobaan ke-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk membuat architecture\n",
    "model4 = Sequential()\n",
    "\n",
    "# Untuk membuat input layer\n",
    "model4.add(Dense(units = 12, activation = 'relu', input_shape = (x_train.shape[1],)))\n",
    "\n",
    "# Untuk membuat hidden layer\n",
    "model4.add(Dense(units = 512, activation = 'relu'))\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Dense(units = 256, activation = 'relu'))\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Dense(units = 128, activation = 'relu'))\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Dense(units = 64, activation = 'relu'))\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Dense(units = 32, activation = 'relu'))\n",
    "\n",
    "# Untuk membuat output layer\n",
    "model4.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada input layer, model menggunakan 12 unit neuron sesuai dengan jumlah fitur atau variabel pada dataset dengan activation function ReLU.\n",
    "\n",
    "Pada hidden layer, model atau layer pertama menggunakan 512 unit neuron, kemudian layer kedua menggunakan 256 unit neuron, dan layer berikutnya menggunakan n/2 unit neuron hingga layer terakhir menggunakan 32 unit neuron dengan activation function ReLU. Lalu, saya juga menambahkan layer Dropout.\n",
    "\n",
    "Alasan saya memakai activation function relu pada input dan hidden layer adalah karena ReLU memiliki performa yang lebih cepat daripada sigmoid.\n",
    "\n",
    "Alasan saya menambahkan layer Dropout adalah karena selain dapat membantu mengurangi overfitting juga dapat membantu mengatasi underfitting dengan memberikan variasi selama pelatihan.\n",
    "\n",
    "Perbedaan model ini dengan model sebelumnya adalah saya menambahkan layer Dropout.\n",
    "\n",
    "Pada output layer, model menggunakan 1 unit neuron dengan activation function sigmoid sesuai dengan task dari dataset ini, yaitu binary classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk mengatur parameter pada optimizer Adam\n",
    "optimizer = Adam(learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disini saya menggunakan optimizer Adam yang mana saya sudah mencoba untuk mengganti learning rate nya berkali-kali. Namun, diperoleh hasil yang paling baik yang menggunakan nilai defaultnya, yaitu 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk mengcompile model\n",
    "model4.compile(optimizer = optimizer,\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter yang digunakan pada saat mengompile model antara lain adalah optimizer \"Adam\" karena memberikan performa yang lebih baik, kemudian loss \"BinaryCrossentropy\" karena ada dua kelas pada variabel \"Target\" dimana labelnya bukan merupakan One Hot dan mengikuti activation function softmax, serta yang terakhir metrics \"Accuracy\" untuk menampilkan accuracy yang diperoleh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 2s 40ms/step - loss: 2.4952 - accuracy: 0.5766 - val_loss: 0.5721 - val_accuracy: 0.8065\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.6933 - accuracy: 0.6129 - val_loss: 0.5633 - val_accuracy: 0.7097\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.3184 - accuracy: 0.5927 - val_loss: 0.5987 - val_accuracy: 0.6774\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.1464 - accuracy: 0.6089 - val_loss: 0.6291 - val_accuracy: 0.7419\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8840 - accuracy: 0.6008 - val_loss: 0.6374 - val_accuracy: 0.6774\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9153 - accuracy: 0.6129 - val_loss: 0.5855 - val_accuracy: 0.7097\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8339 - accuracy: 0.6452 - val_loss: 0.5692 - val_accuracy: 0.6774\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8070 - accuracy: 0.6169 - val_loss: 0.5760 - val_accuracy: 0.5806\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6268 - accuracy: 0.6573 - val_loss: 0.5715 - val_accuracy: 0.6452\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6098 - accuracy: 0.6895 - val_loss: 0.5187 - val_accuracy: 0.6129\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5921 - accuracy: 0.6855 - val_loss: 0.4692 - val_accuracy: 0.6129\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6100 - accuracy: 0.6653 - val_loss: 0.4577 - val_accuracy: 0.7742\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6182 - accuracy: 0.6331 - val_loss: 0.4618 - val_accuracy: 0.7742\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5189 - accuracy: 0.7056 - val_loss: 0.4662 - val_accuracy: 0.8065\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5814 - accuracy: 0.6573 - val_loss: 0.4920 - val_accuracy: 0.8065\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5322 - accuracy: 0.7097 - val_loss: 0.5171 - val_accuracy: 0.7742\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5560 - accuracy: 0.6532 - val_loss: 0.5005 - val_accuracy: 0.7742\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5522 - accuracy: 0.6855 - val_loss: 0.4677 - val_accuracy: 0.7419\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5589 - accuracy: 0.6935 - val_loss: 0.4328 - val_accuracy: 0.7742\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5202 - accuracy: 0.7379 - val_loss: 0.4293 - val_accuracy: 0.8065\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5299 - accuracy: 0.7339 - val_loss: 0.4220 - val_accuracy: 0.8065\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5153 - accuracy: 0.7258 - val_loss: 0.4190 - val_accuracy: 0.8065\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4654 - accuracy: 0.7500 - val_loss: 0.4127 - val_accuracy: 0.8065\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5069 - accuracy: 0.7258 - val_loss: 0.4096 - val_accuracy: 0.8065\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4641 - accuracy: 0.7419 - val_loss: 0.4040 - val_accuracy: 0.7742\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4716 - accuracy: 0.7581 - val_loss: 0.3945 - val_accuracy: 0.8065\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4919 - accuracy: 0.7540 - val_loss: 0.3890 - val_accuracy: 0.8065\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4146 - accuracy: 0.7863 - val_loss: 0.3843 - val_accuracy: 0.8065\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4900 - accuracy: 0.7056 - val_loss: 0.3836 - val_accuracy: 0.8065\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4495 - accuracy: 0.7500 - val_loss: 0.3791 - val_accuracy: 0.8065\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4649 - accuracy: 0.7782 - val_loss: 0.3797 - val_accuracy: 0.8065\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4540 - accuracy: 0.7823 - val_loss: 0.3782 - val_accuracy: 0.8065\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4584 - accuracy: 0.7581 - val_loss: 0.3758 - val_accuracy: 0.8065\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4240 - accuracy: 0.7863 - val_loss: 0.3810 - val_accuracy: 0.7742\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4638 - accuracy: 0.7500 - val_loss: 0.3810 - val_accuracy: 0.7742\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4416 - accuracy: 0.7702 - val_loss: 0.3810 - val_accuracy: 0.8065\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.4285 - accuracy: 0.7702 - val_loss: 0.3874 - val_accuracy: 0.7742\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4334 - accuracy: 0.7661 - val_loss: 0.3788 - val_accuracy: 0.8065\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4054 - accuracy: 0.7742 - val_loss: 0.3713 - val_accuracy: 0.8065\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4007 - accuracy: 0.7742 - val_loss: 0.3856 - val_accuracy: 0.8065\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3843 - accuracy: 0.7782 - val_loss: 0.3771 - val_accuracy: 0.8065\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4213 - accuracy: 0.7823 - val_loss: 0.3725 - val_accuracy: 0.8065\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3765 - accuracy: 0.8105 - val_loss: 0.3723 - val_accuracy: 0.8065\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3886 - accuracy: 0.8185 - val_loss: 0.3766 - val_accuracy: 0.8065\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4046 - accuracy: 0.7823 - val_loss: 0.3635 - val_accuracy: 0.8065\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4334 - accuracy: 0.7702 - val_loss: 0.3497 - val_accuracy: 0.8065\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3819 - accuracy: 0.7984 - val_loss: 0.3462 - val_accuracy: 0.8065\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3956 - accuracy: 0.7903 - val_loss: 0.3595 - val_accuracy: 0.8065\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4030 - accuracy: 0.7621 - val_loss: 0.3493 - val_accuracy: 0.8065\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4125 - accuracy: 0.7581 - val_loss: 0.3335 - val_accuracy: 0.8065\n"
     ]
    }
   ],
   "source": [
    "# Untuk melakukan training model\n",
    "history4 = model4.fit(x_train, y_train,\n",
    "                    epochs = 50,\n",
    "                    batch_size = 32,\n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah ditrain sebanyak 50 epoch dan menggunakan 32 sampel data setiap batchnya, diperoleh hasil train accuracy nya sebesar 0.7581 dan val accuracy nya sebesar 0.8065. Sementara itu, diperoleh hasil train loss nya sebesar 0.4125 dan val loss nya sebesar 0.3335.\n",
    "\n",
    "Kedua nilai loss yang diperoleh memang memiliki perbedaan yang tidak terlalu signifikan, begitupula dengan kedua nilai accuracy. Namun, nilai train loss lebih besar daripada val loss sehingga terdapat indikasi underfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3489 - accuracy: 0.8065\n",
      "Model 4\n",
      "Test loss     : 0.34892040491104126\n",
      "Test accuracy : 0.8064516186714172\n"
     ]
    }
   ],
   "source": [
    "# Untuk melakukan evaluasi model menggunakan data validation dan training model sebelumnya\n",
    "test_loss4, test_accuracy4 = model4.evaluate(x_test, y_test)\n",
    "print(\"Model 4\")\n",
    "print(f\"Test loss     : \" + str(test_loss4))\n",
    "print(f\"Test accuracy : \" + str(test_accuracy4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah mencoba memprediksi menggunakan model1 dan data testing, diperoleh nilai test accuracy nya sebesar 0.81 dan nilai test loss nya sebesar 0.4. Hal ini berarti model cukup baik dalam memprediksi, tetapi masih bisa ditingkatkan lagi performanya dalam memprediksi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percobaan ke-5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk membuat architecture\n",
    "model5 = Sequential()\n",
    "\n",
    "# Untuk membuat input layer\n",
    "model5.add(Dense(units = 12, activation = 'sigmoid', input_shape = (x_train.shape[1],)))\n",
    "\n",
    "# Untuk membuat hidden layer\n",
    "model5.add(Dense(units = 512, activation = 'relu'))\n",
    "model5.add(Dense(units = 256, activation = 'relu'))\n",
    "model5.add(Dense(units = 128, activation = 'relu'))\n",
    "model5.add(Dropout(0.5))\n",
    "model5.add(Dense(units = 64, activation = 'relu'))\n",
    "model5.add(Dropout(0.5))\n",
    "model5.add(Dense(units = 64, activation = 'relu'))\n",
    "model5.add(Dropout(0.5))\n",
    "\n",
    "# Untuk membuat output layer\n",
    "model5.add(Dense(units = 2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada input layer, model menggunakan 12 unit neuron sesuai dengan jumlah fitur atau variabel pada dataset dengan activation function sigmoid.\n",
    "\n",
    "Pada hidden layer, model atau layer pertama menggunakan 512 unit neuron, kemudian layer kedua menggunakan 256 unit neuron, dan layer berikutnya menggunakan n/2 unit neuron hingga layer terakhir menggunakan 64 unit neuron dengan activation function ReLU. Lalu saya juga menambahkan layer Dropout.\n",
    "\n",
    "Alasan saya memakai activation function ReLU pada input dan hidden layer adalah karena ReLU memiliki performa yang lebih cepat daripada sigmoid.\n",
    "\n",
    "Alasan saya menambahkan layer Dropout adalah karena selain dapat membantu mengurangi overfitting juga dapat membantu mengatasi underfitting dengan memberikan variasi selama pelatihan.\n",
    "\n",
    "Pada output layer, model menggunakan 2 unit neuron dengan activation function softmax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk mengatur parameter pada optimizer SGD\n",
    "optimizer = Adam(learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disini saya menggunakan optimizer Adam yang mana saya sudah mencoba untuk mengganti learning rate nya berkali-kali. Namun, diperoleh hasil yang paling baik yang menggunakan nilai defaultnya,  yaitu 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk mengcompile model\n",
    "model5.compile(optimizer = optimizer,\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter yang digunakan pada saat mengompile model antara lain adalah optimizer \"Adam\" karena memberikan performa yang lebih baik, kemudian loss \"SparseCategoricalCrossentropy\" karena ada dua kelas pada variabel \"Target\" dimana labelnya bukan merupakan One Hot dan mengikuti activation function softmax, serta yang terakhir metrics \"Accuracy\" untuk menampilkan accuracy yang diperoleh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk menginisialisasi callback\n",
    "callback_lr = ReduceLROnPlateau(monitor ='val_loss',\n",
    "                                factor = 0.2,\n",
    "                                patience = 3,\n",
    "                                min_lr = 1e-6,\n",
    "                                verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model akan melakukan pengurangan nilai learning rate sebesar learning rate dikalikan 0.2 apabila nilai val loss tidak berubah setelah 3 epoch. Minimum nilai learning rate yang ditentukan adalah sebesar 1^e-6, jika learning rate telah sampai pada batas minimum maka learning rate tidak akan dikurangi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 73ms/step - loss: 0.6924 - accuracy: 0.5444 - val_loss: 0.6354 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6560 - accuracy: 0.6169 - val_loss: 0.5861 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6180 - accuracy: 0.6573 - val_loss: 0.5611 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6024 - accuracy: 0.6855 - val_loss: 0.5382 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5966 - accuracy: 0.6613 - val_loss: 0.5062 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5304 - accuracy: 0.6815 - val_loss: 0.4751 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5013 - accuracy: 0.6976 - val_loss: 0.4693 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4934 - accuracy: 0.6774 - val_loss: 0.4553 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4912 - accuracy: 0.6855 - val_loss: 0.4531 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4910 - accuracy: 0.6935 - val_loss: 0.4432 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4631 - accuracy: 0.7056 - val_loss: 0.4550 - val_accuracy: 0.6774 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4563 - accuracy: 0.7056 - val_loss: 0.4744 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3635 - accuracy: 0.8125\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4815 - accuracy: 0.6895 - val_loss: 0.4560 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4653 - accuracy: 0.7056 - val_loss: 0.4512 - val_accuracy: 0.7419 - lr: 2.0000e-04\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4453 - accuracy: 0.7097 - val_loss: 0.4542 - val_accuracy: 0.7097 - lr: 2.0000e-04\n",
      "Epoch 16/50\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.5418 - accuracy: 0.6094\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4822 - accuracy: 0.6774 - val_loss: 0.4589 - val_accuracy: 0.7097 - lr: 2.0000e-04\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4652 - accuracy: 0.7298 - val_loss: 0.4593 - val_accuracy: 0.7097 - lr: 4.0000e-05\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4634 - accuracy: 0.7056 - val_loss: 0.4597 - val_accuracy: 0.7097 - lr: 4.0000e-05\n",
      "Epoch 19/50\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.4694 - accuracy: 0.7500\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4653 - accuracy: 0.7016 - val_loss: 0.4614 - val_accuracy: 0.7097 - lr: 4.0000e-05\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4786 - accuracy: 0.6895 - val_loss: 0.4615 - val_accuracy: 0.7097 - lr: 8.0000e-06\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4612 - accuracy: 0.6935 - val_loss: 0.4619 - val_accuracy: 0.7097 - lr: 8.0000e-06\n",
      "Epoch 22/50\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3721 - accuracy: 0.7969\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4828 - accuracy: 0.7056 - val_loss: 0.4623 - val_accuracy: 0.7097 - lr: 8.0000e-06\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4823 - accuracy: 0.6855 - val_loss: 0.4623 - val_accuracy: 0.7097 - lr: 1.6000e-06\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4725 - accuracy: 0.7258 - val_loss: 0.4623 - val_accuracy: 0.7097 - lr: 1.6000e-06\n",
      "Epoch 25/50\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.4060 - accuracy: 0.7500\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4479 - accuracy: 0.7339 - val_loss: 0.4624 - val_accuracy: 0.7097 - lr: 1.6000e-06\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4644 - accuracy: 0.7500 - val_loss: 0.4624 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4770 - accuracy: 0.7177 - val_loss: 0.4624 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4710 - accuracy: 0.7581 - val_loss: 0.4623 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4665 - accuracy: 0.7258 - val_loss: 0.4623 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4503 - accuracy: 0.7500 - val_loss: 0.4623 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4329 - accuracy: 0.7298 - val_loss: 0.4623 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4626 - accuracy: 0.7097 - val_loss: 0.4624 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4606 - accuracy: 0.7258 - val_loss: 0.4624 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4605 - accuracy: 0.7016 - val_loss: 0.4625 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4582 - accuracy: 0.7016 - val_loss: 0.4625 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4645 - accuracy: 0.7379 - val_loss: 0.4626 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4620 - accuracy: 0.7137 - val_loss: 0.4626 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4488 - accuracy: 0.7177 - val_loss: 0.4626 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4623 - accuracy: 0.7137 - val_loss: 0.4627 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4659 - accuracy: 0.6855 - val_loss: 0.4627 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4684 - accuracy: 0.7218 - val_loss: 0.4627 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4608 - accuracy: 0.7419 - val_loss: 0.4628 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4491 - accuracy: 0.7177 - val_loss: 0.4628 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4464 - accuracy: 0.7339 - val_loss: 0.4629 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4735 - accuracy: 0.7016 - val_loss: 0.4629 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4562 - accuracy: 0.7298 - val_loss: 0.4630 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4521 - accuracy: 0.7621 - val_loss: 0.4630 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4543 - accuracy: 0.6976 - val_loss: 0.4630 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4606 - accuracy: 0.7500 - val_loss: 0.4631 - val_accuracy: 0.7097 - lr: 1.0000e-06\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4601 - accuracy: 0.7137 - val_loss: 0.4631 - val_accuracy: 0.7097 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "# Untuk melakukan training model\n",
    "history5 = model5.fit(x_train, y_train,\n",
    "                    epochs = 50,\n",
    "                    batch_size = 64,\n",
    "                    callbacks = callback_lr,\n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah ditrain sebanyak 50 epoch dan menggunakan 32 sampel data setiap batchnya, diperoleh hasil train accuracy nya sebesar 0.7137 dan val accuracy nya sebesar 0.7097. Sementara itu, diperoleh hasil train loss nya sebesar 0.4601 dan val loss nya sebesar 0.4631.\n",
    "\n",
    "Kedua nilai loss yang diperoleh memang memiliki perbedaan yang tidak terlalu signifikan, begitupula dengan kedua nilai accuracy. Model ini bisa dikatakan good fit, tetapi masih bida ditingkatkan lagi performa nya dengan menurunkan nilai loss dan meningkatkan nilai accuracy nya.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3372 - accuracy: 0.8065\n",
      "Model 5\n",
      "Test loss     : 0.33722907304763794\n",
      "Test accuracy : 0.8064516186714172\n"
     ]
    }
   ],
   "source": [
    "# Untuk melakukan evaluasi model menggunakan data validation dan training model sebelumnya\n",
    "test_loss5, test_accuracy5 = model5.evaluate(x_test, y_test)\n",
    "print(\"Model 5\")\n",
    "print(f\"Test loss     : \" + str(test_loss5))\n",
    "print(f\"Test accuracy : \" + str(test_accuracy5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah mencoba memprediksi menggunakan model5 dan data testing, diperoleh nilai test accuracy nya sebesar 0.81 dan nilai test loss nya sebesar 0.34. Hal ini berarti model cukup baik dalam memprediksi, tetapi masih bisa ditingkatkan lagi performanya dalam memprediksi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percobaan ke-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk membuat architecture\n",
    "model6 = Sequential()\n",
    "\n",
    "# Untuk membuat input layer\n",
    "model6.add(Dense(units = 12, activation = 'relu', input_shape = (x_train.shape[1],)))\n",
    "\n",
    "# Untuk membuat hidden layer\n",
    "model6.add(Dense(units = 512, activation = 'relu'))\n",
    "model6.add(Dropout(0.5))\n",
    "model6.add(Dense(units = 256, activation = 'relu'))\n",
    "model6.add(Dropout(0.5))\n",
    "model6.add(Dense(units = 128, activation = 'relu'))\n",
    "model6.add(Dropout(0.5))\n",
    "model6.add(Dense(units = 64, activation = 'relu'))\n",
    "model6.add(Dropout(0.5))\n",
    "\n",
    "# Untuk membuat output layer\n",
    "model6.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada input layer, model menggunakan 12 unit neuron sesuai dengan jumlah fitur atau variabel pada dataset dengan activation function ReLU.\n",
    "\n",
    "Pada hidden layer, model atau layer pertama menggunakan 512 unit neuron, kemudian layer kedua menggunakan 256 unit neuron, dan layer berikutnya menggunakan n/2 unit neuron hingga layer terakhir menggunakan 64 unit neuron dengan activation function ReLU. Lalu saya juga menambahkan layer Dropout.\n",
    "\n",
    "Alasan saya memakai activation function relu pada input dan hidden layer adalah karena ReLU memiliki performa yang lebih cepat daripada sigmoid.\n",
    "\n",
    "Alasan saya menambahkan layer Dropout adalah karena selain dapat membantu mengurangi overfitting juga dapat membantu mengatasi underfitting dengan memberikan variasi selama pelatihan.\n",
    "\n",
    "Pada output layer, model menggunakan 1 unit neuron dengan activation function sigmoid sesuai dengan task dari dataset ini, yaitu binary classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk mengcompile model\n",
    "model6.compile(optimizer = 'adam',\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disini saya menggunakan optimizer Adam yang mana saya sudah mencoba untuk mengganti learning rate nya berkali-kali. Namun, diperoleh hasil yang paling baik yang menggunakan nilai defaultnya,  yaitu 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk menginisialisasi callback\n",
    "callback_lr = ReduceLROnPlateau(monitor ='loss',\n",
    "                                factor = 0.2,\n",
    "                                patience = 5,\n",
    "                                min_lr = 1e-6,\n",
    "                                verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model akan melakukan pengurangan nilai learning rate sebesar learning rate dikalikan 0.2 apabila nilai train loss tidak berubah setelah 5 epoch. Minimum nilai learning rate yang ditentukan adalah sebesar 1^e-6, jika learning rate telah sampai pada batas minimum maka learning rate tidak akan dikurangi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 4s 440ms/step - loss: 1.8232 - accuracy: 0.5565 - val_loss: 0.5286 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.3670 - accuracy: 0.5847 - val_loss: 0.5495 - val_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0545 - accuracy: 0.5323 - val_loss: 0.5488 - val_accuracy: 0.8065 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8389 - accuracy: 0.5968 - val_loss: 0.5323 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.7282 - accuracy: 0.6169 - val_loss: 0.5571 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7382 - accuracy: 0.6169 - val_loss: 0.5795 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6688 - accuracy: 0.6129 - val_loss: 0.5822 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6307 - accuracy: 0.6573 - val_loss: 0.5562 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6139 - accuracy: 0.6734 - val_loss: 0.5289 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6209 - accuracy: 0.6855 - val_loss: 0.5177 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6042 - accuracy: 0.6250 - val_loss: 0.5219 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6188 - accuracy: 0.6452 - val_loss: 0.5070 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5779 - accuracy: 0.6855 - val_loss: 0.5007 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6010 - accuracy: 0.6492 - val_loss: 0.4909 - val_accuracy: 0.8065 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5619 - accuracy: 0.6895 - val_loss: 0.4705 - val_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5259 - accuracy: 0.7097 - val_loss: 0.4506 - val_accuracy: 0.8065 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5454 - accuracy: 0.6815 - val_loss: 0.4329 - val_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5364 - accuracy: 0.6694 - val_loss: 0.4197 - val_accuracy: 0.8387 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5021 - accuracy: 0.7218 - val_loss: 0.4149 - val_accuracy: 0.8065 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5172 - accuracy: 0.7056 - val_loss: 0.4124 - val_accuracy: 0.8065 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4844 - accuracy: 0.6935 - val_loss: 0.4081 - val_accuracy: 0.8387 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4866 - accuracy: 0.6895 - val_loss: 0.4024 - val_accuracy: 0.8065 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5072 - accuracy: 0.6734 - val_loss: 0.3851 - val_accuracy: 0.8065 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4623 - accuracy: 0.7258 - val_loss: 0.3752 - val_accuracy: 0.8065 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4799 - accuracy: 0.7298 - val_loss: 0.3826 - val_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4626 - accuracy: 0.7258 - val_loss: 0.3895 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5052 - accuracy: 0.7218 - val_loss: 0.3865 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4497 - accuracy: 0.7460 - val_loss: 0.3760 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4711 - accuracy: 0.7097 - val_loss: 0.3601 - val_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4198 - accuracy: 0.7540 - val_loss: 0.3479 - val_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4392 - accuracy: 0.8024 - val_loss: 0.3316 - val_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4679 - accuracy: 0.7258 - val_loss: 0.3214 - val_accuracy: 0.8065 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4322 - accuracy: 0.7540 - val_loss: 0.3169 - val_accuracy: 0.8065 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4788 - accuracy: 0.7339 - val_loss: 0.3184 - val_accuracy: 0.8065 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.4384 - accuracy: 0.7188\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4460 - accuracy: 0.7419 - val_loss: 0.3243 - val_accuracy: 0.8065 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4295 - accuracy: 0.7702 - val_loss: 0.3236 - val_accuracy: 0.8065 - lr: 2.0000e-04\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4417 - accuracy: 0.7540 - val_loss: 0.3221 - val_accuracy: 0.8065 - lr: 2.0000e-04\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4016 - accuracy: 0.7742 - val_loss: 0.3210 - val_accuracy: 0.8387 - lr: 2.0000e-04\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4180 - accuracy: 0.7661 - val_loss: 0.3197 - val_accuracy: 0.8387 - lr: 2.0000e-04\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4188 - accuracy: 0.7984 - val_loss: 0.3185 - val_accuracy: 0.8387 - lr: 2.0000e-04\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4277 - accuracy: 0.7661 - val_loss: 0.3172 - val_accuracy: 0.8065 - lr: 2.0000e-04\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4141 - accuracy: 0.7944 - val_loss: 0.3159 - val_accuracy: 0.8065 - lr: 2.0000e-04\n",
      "Epoch 43/50\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.3074 - accuracy: 0.8438\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4260 - accuracy: 0.7540 - val_loss: 0.3136 - val_accuracy: 0.8387 - lr: 2.0000e-04\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4223 - accuracy: 0.7621 - val_loss: 0.3134 - val_accuracy: 0.8387 - lr: 4.0000e-05\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4105 - accuracy: 0.7702 - val_loss: 0.3131 - val_accuracy: 0.8387 - lr: 4.0000e-05\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4243 - accuracy: 0.7782 - val_loss: 0.3130 - val_accuracy: 0.8387 - lr: 4.0000e-05\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4172 - accuracy: 0.7823 - val_loss: 0.3131 - val_accuracy: 0.8387 - lr: 4.0000e-05\n",
      "Epoch 48/50\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.3983 - accuracy: 0.6875\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4093 - accuracy: 0.7621 - val_loss: 0.3132 - val_accuracy: 0.8387 - lr: 4.0000e-05\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4011 - accuracy: 0.8024 - val_loss: 0.3132 - val_accuracy: 0.8387 - lr: 8.0000e-06\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4044 - accuracy: 0.7863 - val_loss: 0.3132 - val_accuracy: 0.8387 - lr: 8.0000e-06\n"
     ]
    }
   ],
   "source": [
    "# Untuk melakukan training model\n",
    "history6 = model6.fit(x_train, y_train,\n",
    "                    epochs = 50,\n",
    "                    batch_size = 32,\n",
    "                    callbacks = callback_lr,\n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah ditrain sebanyak 50 epoch dan menggunakan 32 sampel data setiap batchnya, diperoleh hasil train accuracy nya sebesar 0.7863 dan val accuracy nya sebesar 0.8387. Sementara itu, diperoleh hasil train loss nya sebesar 0.4044 dan val loss nya sebesar 0.3132.\n",
    "\n",
    "Kedua nilai loss yang diperoleh memang memiliki perbedaan yang tidak terlalu signifikan, begitupula dengan kedua nilai accuracy. Namun, nilai train loss lebih besar daripada val loss sehingga terdapat indikasi underfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3810 - accuracy: 0.8065\n",
      "Model 6\n",
      "Test loss     : 0.3810182809829712\n",
      "Test accuracy : 0.8064516186714172\n"
     ]
    }
   ],
   "source": [
    "# Untuk melakukan evaluasi model menggunakan data validation dan training model sebelumnya\n",
    "test_loss6, test_accuracy6 = model6.evaluate(x_test, y_test)\n",
    "print(\"Model 6\")\n",
    "print(f\"Test loss     : \" + str(test_loss6))\n",
    "print(f\"Test accuracy : \" + str(test_accuracy6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah mencoba memprediksi menggunakan model1 dan data testing, diperoleh nilai test accuracy nya sebesar 0.81 dan nilai test loss nya sebesar 0.38. Hal ini berarti model cukup baik dalam memprediksi, tetapi masih bisa ditingkatkan lagi performanya dalam memprediksi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percobaan ke-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk membuat architecture\n",
    "model7 = Sequential()\n",
    "\n",
    "# Untuk membuat input layer\n",
    "model7.add(Dense(units = 12, activation = 'relu', input_shape = (x_train.shape[1],)))\n",
    "\n",
    "# Untuk membuat hidden layer\n",
    "model7.add(Dense(units = 1024, activation = 'relu'))\n",
    "model7.add(Dense(units = 512, activation = 'relu'))\n",
    "model7.add(Dense(units = 256, activation = 'relu'))\n",
    "model7.add(Dropout(0.5))\n",
    "model7.add(Dense(units = 128, activation = 'relu'))\n",
    "model7.add(Dropout(0.5))\n",
    "model7.add(Dense(units = 64, activation = 'relu'))\n",
    "model7.add(Dropout(0.5))\n",
    "\n",
    "# Untuk membuat output layer\n",
    "model7.add(Dense(units = 2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada input layer, model menggunakan 12 unit neuron sesuai dengan jumlah fitur atau variabel pada dataset dengan activation function ReLU.\n",
    "\n",
    "Pada hidden layer, model atau layer pertama menggunakan 1024 unit neuron, kemudian layer kedua menggunakan 512 unit neuron, dan layer berikutnya menggunakan n/2 unit neuron hingga layer terakhir menggunakan 64 unit neuron dengan activation function ReLU. Lalu saya juga menambahkan layer Dropout.\n",
    "\n",
    "Alasan saya memakai activation function relu pada input dan hidden layer adalah karena ReLU memiliki performa yang lebih cepat daripada sigmoid.\n",
    "\n",
    "Alasan saya menambahkan layer Dropout adalah karena selain dapat membantu mengurangi overfitting juga dapat membantu mengatasi underfitting dengan memberikan variasi selama pelatihan.\n",
    "\n",
    "Perbedaan model ini dengan model sebelumnya adalah saya menambahkan layer Dropout.\n",
    "\n",
    "Pada output layer, model menggunakan 2 unit neuron dengan activation function softmax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk mengatur parameter pada optimizer Adam\n",
    "optimizer = Adam(learning_rate = 0.001,\n",
    "                 weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disini saya menggunakan optimizer Adam yang mana saya sudah mencoba untuk mengganti learning rate nya berkali-kali. Namun, diperoleh hasil yang paling baik yang menggunakan nilai defaultnya,  yaitu 0.001. Selain itu, saya juga menambahkan weight decay sebesar 0.01 untuk menghindari overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk mengcompile model\n",
    "model7.compile(optimizer = optimizer,\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter yang digunakan pada saat mengompile model antara lain adalah optimizer \"Adam\" karena memberikan performa yang lebih baik, kemudian loss \"SparseCategoricalCrossentropy\" karena ada dua kelas pada variabel \"Target\" dimana labelnya bukan merupakan One Hot dan mengikuti activation function softmax, serta yang terakhir metrics \"Accuracy\" untuk menampilkan accuracy yang diperoleh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk menginisialisasi callback\n",
    "callback_lr = ReduceLROnPlateau(monitor ='val_loss',\n",
    "                                factor = 0.2,\n",
    "                                patience = 5,\n",
    "                                min_lr = 1e-6,\n",
    "                                verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model akan melakukan pengurangan nilai learning rate sebesar learning rate dikalikan 0.2 apabila nilai val loss tidak berubah setelah 5 epoch. Minimum nilai learning rate yang ditentukan adalah sebesar 1^e-6, jika learning rate telah sampai pada batas minimum maka learning rate tidak akan dikurangi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 2s 44ms/step - loss: 1.8641 - accuracy: 0.6008 - val_loss: 0.4836 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.8337 - accuracy: 0.5847 - val_loss: 0.3664 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.2002 - accuracy: 0.6774 - val_loss: 0.3055 - val_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.6439 - accuracy: 0.7097 - val_loss: 0.3048 - val_accuracy: 0.8065 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5779 - accuracy: 0.6815 - val_loss: 0.3030 - val_accuracy: 0.8387 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5476 - accuracy: 0.7056 - val_loss: 0.3150 - val_accuracy: 0.8387 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.4477 - accuracy: 0.7500 - val_loss: 0.3063 - val_accuracy: 0.8387 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5072 - accuracy: 0.7339 - val_loss: 0.3037 - val_accuracy: 0.8387 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.4730 - accuracy: 0.7298 - val_loss: 0.3027 - val_accuracy: 0.8387 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.4293 - accuracy: 0.7621 - val_loss: 0.3168 - val_accuracy: 0.8387 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.4524 - accuracy: 0.7419 - val_loss: 0.3082 - val_accuracy: 0.8387 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.4221 - accuracy: 0.7540 - val_loss: 0.3076 - val_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.4186 - accuracy: 0.7702 - val_loss: 0.3115 - val_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3844 - accuracy: 0.8105\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3844 - accuracy: 0.8105 - val_loss: 0.3131 - val_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3592 - accuracy: 0.8226 - val_loss: 0.3146 - val_accuracy: 0.7742 - lr: 2.0000e-04\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4290 - accuracy: 0.7702 - val_loss: 0.3165 - val_accuracy: 0.7742 - lr: 2.0000e-04\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3935 - accuracy: 0.7984 - val_loss: 0.3172 - val_accuracy: 0.8065 - lr: 2.0000e-04\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3796 - accuracy: 0.7621 - val_loss: 0.3195 - val_accuracy: 0.8065 - lr: 2.0000e-04\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3394 - accuracy: 0.8105\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3394 - accuracy: 0.8105 - val_loss: 0.3161 - val_accuracy: 0.8065 - lr: 2.0000e-04\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3507 - accuracy: 0.8145 - val_loss: 0.3156 - val_accuracy: 0.8065 - lr: 4.0000e-05\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.4058 - accuracy: 0.7419 - val_loss: 0.3157 - val_accuracy: 0.8065 - lr: 4.0000e-05\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3855 - accuracy: 0.7903 - val_loss: 0.3159 - val_accuracy: 0.8065 - lr: 4.0000e-05\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3632 - accuracy: 0.8065 - val_loss: 0.3156 - val_accuracy: 0.8065 - lr: 4.0000e-05\n",
      "Epoch 24/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.3758 - accuracy: 0.7902\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3744 - accuracy: 0.7823 - val_loss: 0.3155 - val_accuracy: 0.8065 - lr: 4.0000e-05\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3377 - accuracy: 0.7984 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 8.0000e-06\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 0.3722 - accuracy: 0.8065 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 8.0000e-06\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3412 - accuracy: 0.8105 - val_loss: 0.3153 - val_accuracy: 0.8065 - lr: 8.0000e-06\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3576 - accuracy: 0.8145 - val_loss: 0.3153 - val_accuracy: 0.8065 - lr: 8.0000e-06\n",
      "Epoch 29/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.3667 - accuracy: 0.8170\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3575 - accuracy: 0.8105 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 8.0000e-06\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3485 - accuracy: 0.8185 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.6000e-06\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3522 - accuracy: 0.8105 - val_loss: 0.3153 - val_accuracy: 0.8065 - lr: 1.6000e-06\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3499 - accuracy: 0.8065 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.6000e-06\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3294 - accuracy: 0.8185 - val_loss: 0.3153 - val_accuracy: 0.8065 - lr: 1.6000e-06\n",
      "Epoch 34/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.3849 - accuracy: 0.7723\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3722 - accuracy: 0.7863 - val_loss: 0.3153 - val_accuracy: 0.8065 - lr: 1.6000e-06\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3475 - accuracy: 0.7984 - val_loss: 0.3153 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.3343 - accuracy: 0.7984 - val_loss: 0.3153 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3696 - accuracy: 0.7944 - val_loss: 0.3153 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3696 - accuracy: 0.7903 - val_loss: 0.3153 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3586 - accuracy: 0.7903 - val_loss: 0.3153 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.3663 - accuracy: 0.8065 - val_loss: 0.3153 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3212 - accuracy: 0.8226 - val_loss: 0.3153 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.3362 - accuracy: 0.8065 - val_loss: 0.3153 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3491 - accuracy: 0.8266 - val_loss: 0.3153 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3585 - accuracy: 0.8105 - val_loss: 0.3153 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.3854 - accuracy: 0.7661 - val_loss: 0.3153 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.3497 - accuracy: 0.7903 - val_loss: 0.3153 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3703 - accuracy: 0.7984 - val_loss: 0.3153 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.3578 - accuracy: 0.7944 - val_loss: 0.3153 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.3719 - accuracy: 0.7702 - val_loss: 0.3153 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.3489 - accuracy: 0.8105 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 0.3850 - accuracy: 0.7984 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3523 - accuracy: 0.8105 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3655 - accuracy: 0.7863 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3769 - accuracy: 0.7702 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.3414 - accuracy: 0.8266 - val_loss: 0.3155 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.3570 - accuracy: 0.7702 - val_loss: 0.3155 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3290 - accuracy: 0.8024 - val_loss: 0.3155 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3410 - accuracy: 0.7984 - val_loss: 0.3155 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.3540 - accuracy: 0.8306 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3527 - accuracy: 0.7903 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3473 - accuracy: 0.8065 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3407 - accuracy: 0.8105 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.3522 - accuracy: 0.8024 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3920 - accuracy: 0.7823 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3674 - accuracy: 0.8024 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3933 - accuracy: 0.7339 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3655 - accuracy: 0.7863 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3316 - accuracy: 0.8024 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3627 - accuracy: 0.7823 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3491 - accuracy: 0.8185 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3698 - accuracy: 0.8145 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3576 - accuracy: 0.8024 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3439 - accuracy: 0.7863 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4228 - accuracy: 0.7903 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3539 - accuracy: 0.8065 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.3405 - accuracy: 0.8306 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3799 - accuracy: 0.7702 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3699 - accuracy: 0.8024 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3330 - accuracy: 0.8024 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3593 - accuracy: 0.8065 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3469 - accuracy: 0.7903 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3648 - accuracy: 0.7702 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3527 - accuracy: 0.8024 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3348 - accuracy: 0.8065 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3604 - accuracy: 0.8024 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.3433 - accuracy: 0.8105 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3456 - accuracy: 0.8226 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3494 - accuracy: 0.7944 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3433 - accuracy: 0.8145 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3395 - accuracy: 0.8145 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.3580 - accuracy: 0.8024 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3588 - accuracy: 0.8024 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3923 - accuracy: 0.8024 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3416 - accuracy: 0.7944 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3478 - accuracy: 0.8145 - val_loss: 0.3154 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3620 - accuracy: 0.7984 - val_loss: 0.3155 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.3604 - accuracy: 0.8145 - val_loss: 0.3155 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3865 - accuracy: 0.7863 - val_loss: 0.3155 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3467 - accuracy: 0.8065 - val_loss: 0.3155 - val_accuracy: 0.8065 - lr: 1.0000e-06\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3447 - accuracy: 0.7944 - val_loss: 0.3155 - val_accuracy: 0.8065 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "history7 = model7.fit(x_train, y_train,\n",
    "                    epochs = 100,\n",
    "                    batch_size = 32,\n",
    "                    callbacks = [callback_lr],\n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah ditrain sebanyak 100 epoch dan menggunakan 32 sampel data setiap batchnya, diperoleh hasil train accuracy nya sebesar 0.7944 dan val accuracy nya sebesar 0.8065. Sementara itu, diperoleh hasil train loss nya sebesar 0.3447 dan val loss nya sebesar 0.3155.\n",
    "\n",
    "Kedua nilai loss yang diperoleh memang memiliki perbedaan yang tidak terlalu signifikan, begitupula dengan kedua nilai accuracy. Namun, nilai train loss lebih besar daripada val loss sehingga terdapat indikasi underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3461 - accuracy: 0.7742\n",
      "Model 7\n",
      "Test loss     : 0.34612008929252625\n",
      "Test accuracy : 0.774193525314331\n"
     ]
    }
   ],
   "source": [
    "# Untuk melakukan evaluasi model menggunakan data validation dan training model sebelumnya\n",
    "test_loss7, test_accuracy7 = model7.evaluate(x_test, y_test)\n",
    "print(\"Model 7\")\n",
    "print(f\"Test loss     : \" + str(test_loss7))\n",
    "print(f\"Test accuracy : \" + str(test_accuracy7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah mencoba memprediksi menggunakan model7 dan data testing, diperoleh nilai test accuracy nya sebesar 0.77 dan nilai test loss nya sebesar 0.35. Hal ini berarti model cukup baik dalam memprediksi, tetapi masih bisa ditingkatkan lagi performanya dalam memprediksi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percobaan ke-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk membuat architecture\n",
    "model8 = Sequential()\n",
    "\n",
    "# Untuk membuat input layer\n",
    "model8.add(Dense(units = 12, activation = 'relu', input_shape = (x_train.shape[1],)))\n",
    "\n",
    "# Untuk membuat hidden layer\n",
    "model8.add(Dense(units = 512, activation = 'relu'))\n",
    "model8.add(Dense(units = 256, activation = 'relu'))\n",
    "model8.add(Dense(units = 128, activation = 'relu'))\n",
    "model8.add(Dense(units = 64, activation = 'relu'))\n",
    "model8.add(Dense(units = 32, activation = 'relu'))\n",
    "model8.add(Dense(units = 16, activation = 'relu'))\n",
    "model8.add(Dense(units = 8, activation = 'relu'))\n",
    "\n",
    "# Untuk membuat output layer\n",
    "model8.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada input layer, model menggunakan 12 unit neuron sesuai dengan jumlah fitur atau variabel pada dataset dengan activation function ReLU.\n",
    "\n",
    "Pada hidden layer, model atau layer pertama menggunakan 512 unit neuron, kemudian layer kedua menggunakan 256 unit neuron, dan layer berikutnya menggunakan n/2 unit neuron hingga layer terakhir menggunakan 8 unit neuron dengan activation function ReLU.\n",
    "\n",
    "Pada output layer, model menggunakan 1 unit neuron dengan activation function sigmoid sesuai dengan task dari dataset ini, yaitu binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate = 1e-2,\n",
    "    decay_steps = 10000,\n",
    "    decay_rate = 0.9)\n",
    "optimizer = keras.optimizers.Adam(learning_rate = lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disini saya menggunakan optimizer Adam dengan mengatur learning rate nya berdasarkan ExponentialDecay. Code ini saya peroleh dari website Keras pada bagian Optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk mengcompile model\n",
    "model8.compile(optimizer = optimizer,\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter yang digunakan pada saat mengompile model1 antara lain adalah optimizer \"Adam\" karena memberikan performa yang lebih baik, kemudian loss \"BinaryCrossentropy\" karena ada dua kelas pada variabel \"Target\" dimana labelnya bukan merupakan One Hot dan mengikuti activation function sigmoid, serta yang terakhir metrics \"Accuracy\" untuk menampilkan accuracy yang diperoleh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 2s 42ms/step - loss: 1.7015 - accuracy: 0.5806 - val_loss: 0.7060 - val_accuracy: 0.3226\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6100 - accuracy: 0.6250 - val_loss: 0.4445 - val_accuracy: 0.7419\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4699 - accuracy: 0.7540 - val_loss: 0.4136 - val_accuracy: 0.7419\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4926 - accuracy: 0.7339 - val_loss: 0.3639 - val_accuracy: 0.7097\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4722 - accuracy: 0.7056 - val_loss: 0.3389 - val_accuracy: 0.8065\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4317 - accuracy: 0.7500 - val_loss: 0.3503 - val_accuracy: 0.8065\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4275 - accuracy: 0.7581 - val_loss: 0.3587 - val_accuracy: 0.8065\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4352 - accuracy: 0.7863 - val_loss: 0.3287 - val_accuracy: 0.7742\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4120 - accuracy: 0.7097 - val_loss: 0.3415 - val_accuracy: 0.8065\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3928 - accuracy: 0.7782 - val_loss: 0.4089 - val_accuracy: 0.7419\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4235 - accuracy: 0.7782 - val_loss: 0.3879 - val_accuracy: 0.8065\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3977 - accuracy: 0.8024 - val_loss: 0.3979 - val_accuracy: 0.7097\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3426 - accuracy: 0.8306 - val_loss: 0.4034 - val_accuracy: 0.6774\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3374 - accuracy: 0.8266 - val_loss: 0.7402 - val_accuracy: 0.8387\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4838 - accuracy: 0.7661 - val_loss: 0.3601 - val_accuracy: 0.7097\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4098 - accuracy: 0.8266 - val_loss: 0.3495 - val_accuracy: 0.7742\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3699 - accuracy: 0.8468 - val_loss: 0.4208 - val_accuracy: 0.8387\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3861 - accuracy: 0.8145 - val_loss: 0.4086 - val_accuracy: 0.7419\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3115 - accuracy: 0.8468 - val_loss: 0.5703 - val_accuracy: 0.7419\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3392 - accuracy: 0.8710 - val_loss: 0.5018 - val_accuracy: 0.8065\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3958 - accuracy: 0.8145 - val_loss: 0.5291 - val_accuracy: 0.7742\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3662 - accuracy: 0.8306 - val_loss: 0.3918 - val_accuracy: 0.8065\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3560 - accuracy: 0.8347 - val_loss: 0.4679 - val_accuracy: 0.7419\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2948 - accuracy: 0.8468 - val_loss: 0.5313 - val_accuracy: 0.8065\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3589 - accuracy: 0.8548 - val_loss: 0.6332 - val_accuracy: 0.7419\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3432 - accuracy: 0.8508 - val_loss: 0.7143 - val_accuracy: 0.7419\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2737 - accuracy: 0.8831 - val_loss: 0.6451 - val_accuracy: 0.7419\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2755 - accuracy: 0.8710 - val_loss: 0.5635 - val_accuracy: 0.7419\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2721 - accuracy: 0.8548 - val_loss: 0.7350 - val_accuracy: 0.7742\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2991 - accuracy: 0.8669 - val_loss: 0.5501 - val_accuracy: 0.7097\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3065 - accuracy: 0.8468 - val_loss: 0.6575 - val_accuracy: 0.8710\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3024 - accuracy: 0.8347 - val_loss: 0.5255 - val_accuracy: 0.8387\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2687 - accuracy: 0.8790 - val_loss: 0.7988 - val_accuracy: 0.8065\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3127 - accuracy: 0.8669 - val_loss: 0.7414 - val_accuracy: 0.7419\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2996 - accuracy: 0.8548 - val_loss: 0.4290 - val_accuracy: 0.7419\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2763 - accuracy: 0.8710 - val_loss: 0.5234 - val_accuracy: 0.8065\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2576 - accuracy: 0.8427 - val_loss: 0.3977 - val_accuracy: 0.8710\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2322 - accuracy: 0.8871 - val_loss: 0.4548 - val_accuracy: 0.7742\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2640 - accuracy: 0.8589 - val_loss: 0.5484 - val_accuracy: 0.8387\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2577 - accuracy: 0.8871 - val_loss: 0.5959 - val_accuracy: 0.7742\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2628 - accuracy: 0.8669 - val_loss: 0.5152 - val_accuracy: 0.7742\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2207 - accuracy: 0.9073 - val_loss: 0.7666 - val_accuracy: 0.8387\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3264 - accuracy: 0.8750 - val_loss: 0.5323 - val_accuracy: 0.8387\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3459 - accuracy: 0.8226 - val_loss: 0.3747 - val_accuracy: 0.8387\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2796 - accuracy: 0.8629 - val_loss: 0.5912 - val_accuracy: 0.8387\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2677 - accuracy: 0.8831 - val_loss: 0.7461 - val_accuracy: 0.8387\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2802 - accuracy: 0.8669 - val_loss: 0.4242 - val_accuracy: 0.7419\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2277 - accuracy: 0.8911 - val_loss: 0.5725 - val_accuracy: 0.8710\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2382 - accuracy: 0.8952 - val_loss: 0.7870 - val_accuracy: 0.8065\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2484 - accuracy: 0.8831 - val_loss: 0.7137 - val_accuracy: 0.8710\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2289 - accuracy: 0.8871 - val_loss: 0.5198 - val_accuracy: 0.8065\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2039 - accuracy: 0.8952 - val_loss: 0.5319 - val_accuracy: 0.7742\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2013 - accuracy: 0.8911 - val_loss: 0.9544 - val_accuracy: 0.8387\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2011 - accuracy: 0.8992 - val_loss: 0.7678 - val_accuracy: 0.7742\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1762 - accuracy: 0.9073 - val_loss: 0.7663 - val_accuracy: 0.8387\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1826 - accuracy: 0.9032 - val_loss: 0.7797 - val_accuracy: 0.7419\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2316 - accuracy: 0.8952 - val_loss: 0.6309 - val_accuracy: 0.7742\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2051 - accuracy: 0.8911 - val_loss: 0.7916 - val_accuracy: 0.6774\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3082 - accuracy: 0.8387 - val_loss: 0.6873 - val_accuracy: 0.7742\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2538 - accuracy: 0.8831 - val_loss: 0.4946 - val_accuracy: 0.8065\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2705 - accuracy: 0.8750 - val_loss: 0.7342 - val_accuracy: 0.8710\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2451 - accuracy: 0.8992 - val_loss: 0.4647 - val_accuracy: 0.7742\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1968 - accuracy: 0.9073 - val_loss: 0.6881 - val_accuracy: 0.8387\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1699 - accuracy: 0.9274 - val_loss: 0.9831 - val_accuracy: 0.8065\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1760 - accuracy: 0.9073 - val_loss: 0.8789 - val_accuracy: 0.7419\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2231 - accuracy: 0.8911 - val_loss: 0.5369 - val_accuracy: 0.7419\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2368 - accuracy: 0.8790 - val_loss: 0.6205 - val_accuracy: 0.8387\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1712 - accuracy: 0.9113 - val_loss: 0.9766 - val_accuracy: 0.7742\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2008 - accuracy: 0.8992 - val_loss: 0.9157 - val_accuracy: 0.8065\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2086 - accuracy: 0.8831 - val_loss: 0.5584 - val_accuracy: 0.7742\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1620 - accuracy: 0.9234 - val_loss: 0.8043 - val_accuracy: 0.8065\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2150 - accuracy: 0.8750 - val_loss: 0.6105 - val_accuracy: 0.8710\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2192 - accuracy: 0.8952 - val_loss: 0.5306 - val_accuracy: 0.7742\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2510 - accuracy: 0.8911 - val_loss: 0.9228 - val_accuracy: 0.8387\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2383 - accuracy: 0.8911 - val_loss: 0.7935 - val_accuracy: 0.8065\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2086 - accuracy: 0.9032 - val_loss: 0.7253 - val_accuracy: 0.7742\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1713 - accuracy: 0.9315 - val_loss: 1.1490 - val_accuracy: 0.8710\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1541 - accuracy: 0.9234 - val_loss: 1.1820 - val_accuracy: 0.8065\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1548 - accuracy: 0.9194 - val_loss: 1.5307 - val_accuracy: 0.7742\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1816 - accuracy: 0.8992 - val_loss: 0.9563 - val_accuracy: 0.8065\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1735 - accuracy: 0.9234 - val_loss: 0.7360 - val_accuracy: 0.8387\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2116 - accuracy: 0.9234 - val_loss: 0.5771 - val_accuracy: 0.7742\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2145 - accuracy: 0.8992 - val_loss: 1.0570 - val_accuracy: 0.8065\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1966 - accuracy: 0.9032 - val_loss: 0.8565 - val_accuracy: 0.8710\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2117 - accuracy: 0.8871 - val_loss: 0.7215 - val_accuracy: 0.7742\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1755 - accuracy: 0.9113 - val_loss: 0.8393 - val_accuracy: 0.7742\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3292 - accuracy: 0.8548 - val_loss: 0.3358 - val_accuracy: 0.8387\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3140 - accuracy: 0.8710 - val_loss: 0.3170 - val_accuracy: 0.7419\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2928 - accuracy: 0.8831 - val_loss: 0.3029 - val_accuracy: 0.8710\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2226 - accuracy: 0.8669 - val_loss: 0.7767 - val_accuracy: 0.8710\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1782 - accuracy: 0.9194 - val_loss: 1.3661 - val_accuracy: 0.7742\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1474 - accuracy: 0.9355 - val_loss: 1.6017 - val_accuracy: 0.7742\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1385 - accuracy: 0.9355 - val_loss: 1.9888 - val_accuracy: 0.7419\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1361 - accuracy: 0.9395 - val_loss: 0.9034 - val_accuracy: 0.7742\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2438 - accuracy: 0.8790 - val_loss: 0.3141 - val_accuracy: 0.8065\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2725 - accuracy: 0.8710 - val_loss: 0.4514 - val_accuracy: 0.8710\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2075 - accuracy: 0.9153 - val_loss: 0.5136 - val_accuracy: 0.8065\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2118 - accuracy: 0.9113 - val_loss: 0.5708 - val_accuracy: 0.8065\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1842 - accuracy: 0.9073 - val_loss: 0.7159 - val_accuracy: 0.7419\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2478 - accuracy: 0.8508 - val_loss: 0.7586 - val_accuracy: 0.7419\n"
     ]
    }
   ],
   "source": [
    "history8 = model8.fit(x_train, y_train,\n",
    "                    epochs = 100,\n",
    "                    batch_size = 32,\n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah ditrain sebanyak 100 epoch dan menggunakan 32 sampel data setiap batchnya, diperoleh hasil train accuracy nya sebesar 0.8508 dan val accuracy nya sebesar 0.7419. Sementara itu, diperoleh hasil train loss nya sebesar 0.2478 dan val loss nya sebesar 0.7586.\n",
    "\n",
    "Kedua nilai loss yang diperoleh memiliki perbedaan yang signifikan, begitupula dengan kedua nilai accuracy. Selain itu, nilai train loss jauh lebih kecil daripada val loss sehingga terdapat indikasi overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4864 - accuracy: 0.6774\n",
      "Model 8\n",
      "Test loss     : 0.4863725006580353\n",
      "Test accuracy : 0.6774193644523621\n"
     ]
    }
   ],
   "source": [
    "# Untuk melakukan evaluasi model menggunakan data validation dan training model sebelumnya\n",
    "test_loss8, test_accuracy8 = model8.evaluate(x_test, y_test)\n",
    "print(\"Model 8\")\n",
    "print(f\"Test loss     : \" + str(test_loss8))\n",
    "print(f\"Test accuracy : \" + str(test_accuracy8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah mencoba memprediksi menggunakan model8 dan data testing, diperoleh nilai test accuracy nya sebesar 0.68 dan nilai test loss nya sebesar 0.49. Hal ini berarti model belum cukup baik dalam memprediksi dan harus ditingkatkan lagi performanya dalam memprediksi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percobaan ke-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk membuat architecture\n",
    "model9 = Sequential()\n",
    "\n",
    "# Untuk membuat input layer\n",
    "model9.add(Dense(units = 12, activation = 'relu', input_shape = (x_train.shape[1],)))\n",
    "\n",
    "# Untuk membuat hidden layer\n",
    "model9.add(Dense(units = 1024, activation = 'relu'))\n",
    "model9.add(Dense(units = 512, activation = 'relu'))\n",
    "model9.add(Dense(units = 256, activation = 'relu'))\n",
    "model9.add(Dense(units = 128, activation = 'relu'))\n",
    "\n",
    "# Untuk membuat output layer\n",
    "model9.add(Dense(units = 2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada input layer, model menggunakan 12 unit neuron sesuai dengan jumlah fitur atau variabel pada dataset dengan activation function ReLU.\n",
    "\n",
    "Pada hidden layer, model atau layer pertama menggunakan 512 unit neuron, kemudian layer kedua menggunakan 256 unit neuron, dan layer berikutnya menggunakan n/2 unit neuron hingga layer terakhir menggunakan 32 unit neuron dengan activation function ReLU.\n",
    "\n",
    "Perbedaan model ini dengan model sebelumnya adalah saya menambahkan 1 hidden layer derngan jumlah neuron 1024 unit.\n",
    "\n",
    "Pada output layer, model menggunakan 2 unit neuron dengan activation function softmax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk mengatur parameter pada optimizer Adam\n",
    "optimizer = Adam(learning_rate = 0.001,\n",
    "                 weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disini saya menggunakan optimizer Adam yang mana saya sudah mencoba untuk mengganti learning rate nya berkali-kali. Namun, diperoleh hasil yang paling baik yang menggunakan nilai defaultnya, yaitu 0.001. Selain itu, saya juga menambahkan weight decay sebesar 0.01 untuk menghindari overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk mengcompile model\n",
    "model9.compile(optimizer = optimizer,\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter yang digunakan pada saat mengompile model9 antara lain adalah optimizer \"Adam\" karena memberikan performa yang lebih baik, kemudian loss \"SparseCategoricalCrossentropy\" karena ada dua kelas pada variabel \"Target\" dimana labelnya bukan merupakan One Hot dan mengikuti activation function sigmoid, serta yang terakhir metrics \"Accuracy\" untuk menampilkan accuracy yang diperoleh.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk menginisialisasi callback\n",
    "callback_lr = ReduceLROnPlateau(monitor ='val_loss',\n",
    "                                factor = 0.2,\n",
    "                                patience = 5,\n",
    "                                min_lr = 1e-6,\n",
    "                                verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model akan melakukan pengurangan nilai learning rate sebesar learning rate dikalikan 0.2 apabila nilai val loss tidak berubah setelah 5 epoch. Minimum nilai learning rate yang ditentukan adalah sebesar 1^e-6, jika learning rate telah sampai pada batas minimum maka learning rate tidak akan dikurangi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 2s 49ms/step - loss: 2.0551 - accuracy: 0.6048 - val_loss: 0.8642 - val_accuracy: 0.5484 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6382 - accuracy: 0.6734 - val_loss: 0.6572 - val_accuracy: 0.6774 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5360 - accuracy: 0.7581 - val_loss: 0.5218 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4222 - accuracy: 0.7903 - val_loss: 0.4782 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4556 - accuracy: 0.7460 - val_loss: 0.3918 - val_accuracy: 0.8065 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.4226 - accuracy: 0.8065 - val_loss: 0.3484 - val_accuracy: 0.8065 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.4139 - accuracy: 0.7823 - val_loss: 0.5211 - val_accuracy: 0.8065 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.4707 - accuracy: 0.7661 - val_loss: 0.6013 - val_accuracy: 0.8065 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4951 - accuracy: 0.7742 - val_loss: 0.6412 - val_accuracy: 0.8065 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4793 - accuracy: 0.7581 - val_loss: 0.4658 - val_accuracy: 0.8065 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "5/8 [=================>............] - ETA: 0s - loss: 0.4478 - accuracy: 0.8125\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.5021 - accuracy: 0.7863 - val_loss: 0.3749 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3774 - accuracy: 0.7903 - val_loss: 0.3855 - val_accuracy: 0.8710 - lr: 2.0000e-04\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.3496 - accuracy: 0.8105 - val_loss: 0.3531 - val_accuracy: 0.8065 - lr: 2.0000e-04\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3499 - accuracy: 0.8226 - val_loss: 0.3504 - val_accuracy: 0.8065 - lr: 2.0000e-04\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3406 - accuracy: 0.7903 - val_loss: 0.3557 - val_accuracy: 0.8710 - lr: 2.0000e-04\n",
      "Epoch 16/50\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.3329 - accuracy: 0.8036\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3383 - accuracy: 0.7984 - val_loss: 0.3508 - val_accuracy: 0.8387 - lr: 2.0000e-04\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3373 - accuracy: 0.7903 - val_loss: 0.3512 - val_accuracy: 0.8387 - lr: 4.0000e-05\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3354 - accuracy: 0.7984 - val_loss: 0.3499 - val_accuracy: 0.8387 - lr: 4.0000e-05\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3381 - accuracy: 0.8065 - val_loss: 0.3492 - val_accuracy: 0.8387 - lr: 4.0000e-05\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3340 - accuracy: 0.8105 - val_loss: 0.3508 - val_accuracy: 0.8387 - lr: 4.0000e-05\n",
      "Epoch 21/50\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.3322 - accuracy: 0.7946\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3342 - accuracy: 0.7944 - val_loss: 0.3521 - val_accuracy: 0.8710 - lr: 4.0000e-05\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3344 - accuracy: 0.8024 - val_loss: 0.3520 - val_accuracy: 0.8710 - lr: 8.0000e-06\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3345 - accuracy: 0.8024 - val_loss: 0.3513 - val_accuracy: 0.8710 - lr: 8.0000e-06\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3340 - accuracy: 0.7944 - val_loss: 0.3513 - val_accuracy: 0.8710 - lr: 8.0000e-06\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3338 - accuracy: 0.7944 - val_loss: 0.3510 - val_accuracy: 0.8710 - lr: 8.0000e-06\n",
      "Epoch 26/50\n",
      "5/8 [=================>............] - ETA: 0s - loss: 0.3225 - accuracy: 0.7750\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3336 - accuracy: 0.7944 - val_loss: 0.3504 - val_accuracy: 0.8387 - lr: 8.0000e-06\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3335 - accuracy: 0.7984 - val_loss: 0.3504 - val_accuracy: 0.8387 - lr: 1.6000e-06\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3335 - accuracy: 0.7984 - val_loss: 0.3502 - val_accuracy: 0.8387 - lr: 1.6000e-06\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3335 - accuracy: 0.8024 - val_loss: 0.3503 - val_accuracy: 0.8387 - lr: 1.6000e-06\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.3335 - accuracy: 0.8024 - val_loss: 0.3503 - val_accuracy: 0.8387 - lr: 1.6000e-06\n",
      "Epoch 31/50\n",
      "5/8 [=================>............] - ETA: 0s - loss: 0.3521 - accuracy: 0.7937\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.3334 - accuracy: 0.8024 - val_loss: 0.3502 - val_accuracy: 0.8387 - lr: 1.6000e-06\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3334 - accuracy: 0.8024 - val_loss: 0.3502 - val_accuracy: 0.8387 - lr: 1.0000e-06\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.3334 - accuracy: 0.8024 - val_loss: 0.3502 - val_accuracy: 0.8387 - lr: 1.0000e-06\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.3334 - accuracy: 0.8024 - val_loss: 0.3502 - val_accuracy: 0.8387 - lr: 1.0000e-06\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.3335 - accuracy: 0.8024 - val_loss: 0.3501 - val_accuracy: 0.8387 - lr: 1.0000e-06\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.3334 - accuracy: 0.8065 - val_loss: 0.3501 - val_accuracy: 0.8387 - lr: 1.0000e-06\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.3334 - accuracy: 0.8065 - val_loss: 0.3501 - val_accuracy: 0.8387 - lr: 1.0000e-06\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.3334 - accuracy: 0.8065 - val_loss: 0.3501 - val_accuracy: 0.8387 - lr: 1.0000e-06\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3333 - accuracy: 0.8024 - val_loss: 0.3502 - val_accuracy: 0.8387 - lr: 1.0000e-06\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3333 - accuracy: 0.8065 - val_loss: 0.3501 - val_accuracy: 0.8387 - lr: 1.0000e-06\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3333 - accuracy: 0.8065 - val_loss: 0.3501 - val_accuracy: 0.8387 - lr: 1.0000e-06\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3333 - accuracy: 0.8065 - val_loss: 0.3502 - val_accuracy: 0.8387 - lr: 1.0000e-06\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3333 - accuracy: 0.8065 - val_loss: 0.3501 - val_accuracy: 0.8387 - lr: 1.0000e-06\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3333 - accuracy: 0.8065 - val_loss: 0.3501 - val_accuracy: 0.8387 - lr: 1.0000e-06\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3333 - accuracy: 0.8065 - val_loss: 0.3501 - val_accuracy: 0.8387 - lr: 1.0000e-06\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3333 - accuracy: 0.8065 - val_loss: 0.3501 - val_accuracy: 0.8387 - lr: 1.0000e-06\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3333 - accuracy: 0.8065 - val_loss: 0.3501 - val_accuracy: 0.8387 - lr: 1.0000e-06\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3333 - accuracy: 0.8065 - val_loss: 0.3500 - val_accuracy: 0.8387 - lr: 1.0000e-06\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.3333 - accuracy: 0.8065 - val_loss: 0.3501 - val_accuracy: 0.8387 - lr: 1.0000e-06\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.3332 - accuracy: 0.8065 - val_loss: 0.3501 - val_accuracy: 0.8387 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "history9 = model9.fit(x_train, y_train,\n",
    "                    epochs = 50,\n",
    "                    batch_size = 32,\n",
    "                    callbacks = callback_lr,\n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah ditrain sebanyak 50 epoch dan menggunakan 32 sampel data setiap batchnya, diperoleh hasil train accuracy nya sebesar 0.8065 dan val accuracy nya sebesar 0.8387. Sementara itu, diperoleh hasil train loss nya sebesar 0.3332 dan val loss nya sebesar 0.3501.\n",
    "\n",
    "Kedua nilai loss yang diperoleh memang memiliki perbedaan yang tidak terlalu signifikan, begitupula dengan kedua nilai accuracy. Model ini bisa dikatakan just right dan tidak terdapat indikasi overfitting maupun underfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3588 - accuracy: 0.8387\n",
      "Model 9\n",
      "Test loss     : 0.35881006717681885\n",
      "Test accuracy : 0.8387096524238586\n"
     ]
    }
   ],
   "source": [
    "# Untuk melakukan evaluasi model menggunakan data validation dan training model sebelumnya\n",
    "test_loss9, test_accuracy9 = model9.evaluate(x_test, y_test)\n",
    "print(\"Model 9\")\n",
    "print(f\"Test loss     : \" + str(test_loss9))\n",
    "print(f\"Test accuracy : \" + str(test_accuracy9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah mencoba memprediksi menggunakan model9 dan data testing, diperoleh nilai test accuracy nya sebesar 0.84 dan nilai test loss nya sebesar 0.36. Hal ini berarti model cukup baik dalam memprediksi, tetapi masih bisa ditingkatkan lagi performanya dalam memprediksi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library untuk membuat classification report dan confusion matrix pada hasil prediksi\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 90ms/step\n"
     ]
    }
   ],
   "source": [
    "# Untuk melakukan prediksi menggunakan training model sebelumnya\n",
    "predict = model.predict(x_test)\n",
    "y_classes = predict.argmax(axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76        22\n",
      "           1       0.45      0.56      0.50         9\n",
      "\n",
      "    accuracy                           0.68        31\n",
      "   macro avg       0.63      0.64      0.63        31\n",
      "weighted avg       0.70      0.68      0.69        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Untuk menampilkan hasil prediksi menggunakan classification report\n",
    "print(classification_report(y_test, y_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari classification report, terlihat hasil accuracy yang diperoleh secara keseluruhan dalam memprediksi menggunakan model benchmark yang sebelumnya telah ditraining cukup rendah, yaitu 68%.\n",
    "1.   Kategori Abnormal  ->\n",
    "Kategori ini memiliki precision score sebesar 80%, yang artinya dari seluruh gambar yang diprediksi merupakan Abnormal, 80% di antaranya adalah benar. Lalu, kategori ini memiliki recall score sebesar 73%, yang artinya model berhasil memprediksi benar sebesar 73% dari semua gambar Abnormal. Model ini juga memiliki f1-score yang lumayan tinggi, yaitu sebesar 76%.\n",
    "2.   Kategori Normal ->\n",
    "Kategori ini memiliki precision score sebesar 45%, yang artinya dari seluruh gambar yang diprediksi merupakan Normal, 45% di antaranya adalah benar. Lalu, kategori ini memiliki recall score sebesar 56%, yang artinya model berhasil memprediksi benar sebesar 56% dari semua gambar Normal. Model ini juga memiliki f1-score yang cukup rendah, yaitu sebesar 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    }
   ],
   "source": [
    "# Untuk melakukan prediksi menggunakan model 9\n",
    "predict = model9.predict(x_test)\n",
    "y_classes = predict.argmax(axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89        22\n",
      "           1       0.75      0.67      0.71         9\n",
      "\n",
      "    accuracy                           0.84        31\n",
      "   macro avg       0.81      0.79      0.80        31\n",
      "weighted avg       0.83      0.84      0.84        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Untuk menampilkan hasil prediksi menggunakan classification report\n",
    "print(classification_report(y_test, y_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari classification report, terlihat hasil accuracy yang diperoleh secara keseluruhan dalam memprediksi menggunakan model9 yang sebelumnya telah ditraining cukup tinggi, yaitu 84%.\n",
    "1.   Kategori Abnormal  ->\n",
    "Kategori ini memiliki precision score sebesar 87%, yang artinya dari seluruh gambar yang diprediksi merupakan Abnormal, 87% di antaranya adalah benar. Lalu, kategori ini memiliki recall score sebesar 91%, yang artinya model berhasil memprediksi benar sebesar 91% dari semua gambar Abnormal Model ini juga memiliki f1-score yang lumayan tinggi, yaitu sebesar 89%.\n",
    "2.   Kategori Normal ->\n",
    "Kategori ini memiliki precision score sebesar 75%, yang artinya dari seluruh gambar yang diprediksi merupakan Normal, 75% di antaranya adalah benar. Lalu, kategori ini memiliki recall score sebesar 67%, yang artinya model berhasil memprediksi benar sebesar 67% dari semua gambar Normal. Model ini juga memiliki f1-score yang cukup tinggi, yaitu sebesar 71%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kesimpulan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah melakukan evaluasi dan perbandingan terhadap model benchmark dan model yang telah dimodifikasi, ada beberapa hal yang dapat disimpulkan.\n",
    "1. Data imbalanced pada kelas Normal diselesaikan dengan menggunakan teknik oversampling SMOTE.\n",
    "2. Model benchmark yang awalnya underfitting berhasil diselesaikan dengan model yang telah dimodifikasi sehingga menjadi just right.\n",
    "3. Model benchmark memiliki accuracy yang lebih rendah secara keseluruhan ketika diuji menggunakan data testing, tetapi model yang telah dimodifikasi memiliki accuracy yang lebih tinggi secara keseluruhan ketika diuji menggunakan data testing.\n",
    "4. Meskipun telah ada peningkatan accuracy menggunakan model yang telah dimodifikasi, tetapi masih perlu dilakukan evaluasi dan perbaikan lagi khususnya dalam memprediksi kelas Normal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referensi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goswami, Dr. S. (2021, February 19). SMOTE using Python. Medium. https://towardsdatascience.com/applying-smote-for-class-imbalance-with-just-a-few-lines-of-code-python-cdf603e58688 \n",
    "\n",
    "K., P. H. (2017, May 16). Menilik Activation Function. Medium. https://medium.com/@pramestihattak/menilik-activation-functions-7710177a54c9 \n",
    "\n",
    "Keras. (n.d.). Keras documentation: Optimizers. https://keras.io/api/optimizers/ \n",
    "\n",
    "Rutecki, M. (2022, December 29). Best techniques and metrics for Imbalanced Dataset. Kaggle. https://www.kaggle.com/code/marcinrutecki/best-techniques-and-metrics-for-imbalanced-dataset \n",
    "\n",
    "TensorFlow. (2023, October 27). Classification on imbalanced data. TensorFlow. https://www.tensorflow.org/tutorials/structured_data/imbalanced_data \n",
    "\n",
    "Yang, S. (2020, September 4). Deep learning basics&nbsp; -&nbsp; weight decay. Medium. https://medium.com/analytics-vidhya/deep-learning-basics-weight-decay-3c68eb4344e9 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
